{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Pipeline on Local Spark\n",
    "\n",
    "1. Setting up\n",
    "2. Helpers\n",
    "3. Pull stock info\n",
    "4. Pull short interests\n",
    "5. Pull stock prices\n",
    "6. Combine datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting Up\n",
    "\n",
    "We want to have a logging feature that works for both Jupyter notebook and Spark environments.\n",
    "\n",
    "1. As it turned out, Spark has \"WARN\" but does not have \"WARNING\" level, while in current Python (3.6.x), \"WARN\" is deprecated, \"WARNING\" should be used instead.\n",
    "2. Therefore, we create a custom \"WARN\" level as well as function `logger.warn` for Jupyter notebook.\n",
    "3. As shown in [this StackOverflow post](https://stackoverflow.com/questions/35326814/change-level-logged-to-ipython-jupyter-notebook), this is not straightforward due to a Jupyter notebook bug. We need to workaround this by specifying an invalid value first, which we do in the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:The 'log_level' trait of an IPKernelApp instance must be any of (0, 10, 20, 30, 40, 50, 'DEBUG', 'INFO', 'WARN', 'ERROR', 'CRITICAL'), but a value of 'WORKAROUND' <class 'str'> was specified.\n",
      "WARN:root:hello\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['airflow/config.cfg']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Run this, but don't copy into etl scripts\n",
    "# workaround via specifying an invalid value first\n",
    "%config Application.log_level='WORKAROUND'\n",
    "import logging\n",
    "logging.WARN = 21\n",
    "logging.addLevelName(logging.WARN, 'WARN')\n",
    "\n",
    "def warn(self, message, *args, **kws):\n",
    "    if self.isEnabledFor(logging.WARN):\n",
    "        # Yes, logger takes its '*args' as 'args'.\n",
    "        self._log(logging.WARN, message, args, **kws) \n",
    "logging.Logger.warn = warn\n",
    "\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.WARN)\n",
    "logger.warn('hello')\n",
    "\n",
    "# ------------------\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "        .getOrCreate()\n",
    "#         .config(\"spark.eventLog.enabled\", \"true\") \\\n",
    "#         .config(\"spark.eventLog.dir\" \"test_data/spark-logs\") \\\n",
    "\n",
    "import pandas as pd\n",
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read('airflow/config.cfg')\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell, and also copy to all etl scripts, or simply include in common.py\n",
    "\n",
    "import requests\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.sql import Row\n",
    "\n",
    "from py4j.java_gateway import java_import"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Copy this cell content to common.py, but don't run here.\n",
    "\n",
    "Logger = spark._jvm.org.apache.log4j.Logger\n",
    "logger = Logger.getLogger(\"DAG\")\n",
    "spark.sparkContext.setLogLevel('WARN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_path(spark, 's3a://short-interest-effect', '/data/raw/stock_info_nasdaq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Helpers\n",
    "\n",
    "Include this code as helpers in all next etl scripts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS_ACCESS_KEY_ID = config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "AWS_SECRET_ACCESS_KEY = config['AWS']['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py4j.protocol import Py4JJavaError\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", AWS_ACCESS_KEY_ID)\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", AWS_SECRET_ACCESS_KEY)\n",
    "\n",
    "\n",
    "def delete_path(spark, host, path):\n",
    "    sc = spark.sparkContext\n",
    "    java_import(sc._gateway.jvm, \"java.net.URI\")\n",
    "    uri = sc._gateway.jvm.java.net.URI\n",
    "    fs = (sc._jvm.org\n",
    "          .apache.hadoop\n",
    "          .fs.FileSystem\n",
    "          .get(uri(host), sc._jsc.hadoopConfiguration())\n",
    "          )\n",
    "    fs.delete(sc._jvm.org.apache.hadoop.fs.Path(host+path), True)\n",
    "    \n",
    "    \n",
    "def copyMerge(spark, host, src_dir, dst_file, overwrite=False, deleteSource=False, debug=False):\n",
    "    \n",
    "    sc = spark.sparkContext\n",
    "    \n",
    "    hadoop = sc._jvm.org.apache.hadoop\n",
    "#     conf = hadoop.conf.Configuration()\n",
    "    conf = sc._jsc.hadoopConfiguration()\n",
    "#     fs = hadoop.fs.FileSystem.get(conf)\n",
    "    java_import(sc._gateway.jvm, \"java.net.URI\")\n",
    "    uri = sc._gateway.jvm.java.net.URI\n",
    "    fs = (sc._jvm.org\n",
    "          .apache.hadoop\n",
    "          .fs.FileSystem\n",
    "          .get(uri(host), sc._jsc.hadoopConfiguration())\n",
    "          )\n",
    "\n",
    "    # check files that will be merged\n",
    "    files = []\n",
    "    for f in fs.listStatus(hadoop.fs.Path(src_dir)):\n",
    "        if f.isFile():\n",
    "            files.append(f.getPath())\n",
    "    if not files:\n",
    "        raise ValueError(\"Source directory {} is empty\".format(src_dir))\n",
    "    files.sort(key=lambda f: str(f))\n",
    "\n",
    "    # dst_permission = hadoop.fs.permission.FsPermission.valueOf(permission)      # , permission='-rw-r-----'\n",
    "    out_stream = fs.create(hadoop.fs.Path(dst_file), overwrite)\n",
    "\n",
    "    try:\n",
    "        # loop over files in alphabetical order and append them one by one to the target file\n",
    "        for file in files:\n",
    "            if debug: \n",
    "                print(\"Appending file {} into {}\".format(file, dst_file))\n",
    "\n",
    "            in_stream = fs.open(file)   # InputStream object\n",
    "            try:\n",
    "                hadoop.io.IOUtils.copyBytes(in_stream, out_stream, conf, False)     # False means don't close out_stream\n",
    "            finally:\n",
    "                in_stream.close()\n",
    "    finally:\n",
    "        out_stream.close()\n",
    "\n",
    "    if deleteSource:\n",
    "        fs.delete(hadoop.fs.Path(src_dir), True)    # True=recursive\n",
    "        if debug:\n",
    "            print(\"Source directory {} removed.\".format(src_dir))\n",
    "            \n",
    "            \n",
    "def spark_table_exists(host, table_path):\n",
    "    URI           = sc._gateway.jvm.java.net.URI\n",
    "    Path          = sc._gateway.jvm.org.apache.hadoop.fs.Path\n",
    "    FileSystem    = sc._gateway.jvm.org.apache.hadoop.fs.FileSystem\n",
    "    # Configuration = sc._gateway.jvm.org.apache.hadoop.conf.Configuration\n",
    "    Configuration = sc._jsc.hadoopConfiguration\n",
    "\n",
    "\n",
    "    fs = FileSystem.get(URI(host), Configuration())\n",
    "\n",
    "    try:\n",
    "        status = fs.listStatus(Path(table_path))\n",
    "\n",
    "        return True\n",
    "    except Py4JJavaError as e:\n",
    "        if 'FileNotFoundException' in str(e):\n",
    "            return False\n",
    "        else:\n",
    "            print(e)\n",
    "    \n",
    "    \n",
    "def check_basic_quality(logger, host, table_path, table_type='csv'):\n",
    "    \"\"\" Checks quality of DAG.\n",
    "    \n",
    "    We do this by checking if the table exists and is not empty.\n",
    "    \n",
    "    Args:\n",
    "        - table_type(str): 'parquet' or 'csv'\n",
    "    \"\"\"\n",
    "    if not spark_table_exists(host, table_path):\n",
    "        logger.warn(\"(FAIL) Table {} does not exist\".format(host+table_path))\n",
    "    else:\n",
    "        if table_type == 'parquet':\n",
    "            count = spark.read.parquet(host+table_path).count()\n",
    "        elif table_type == 'csv':\n",
    "            count = spark.read.csv(host+table_path, header=True).count()\n",
    "            \n",
    "        if count == 0:\n",
    "            logger.warn(\"(FAIL) Table {} is empty.\".format(host+table_path))\n",
    "        else:\n",
    "            logger.warn(\"(SUCCESS) Table {} has {} rows.\".format(host+table_path, count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARN:root:(FAIL) Table s3a://short-interest-effect/data/test_table does not exist\n"
     ]
    }
   ],
   "source": [
    "print(spark_table_exists('s3a://short-interest-effect', 'data/test_table')) # Fails due to lack of '/' before the table path\n",
    "print(spark_table_exists('s3a://short-interest-effect', '/data/test_table'))\n",
    "print(spark_table_exists('', 'test_data/test_table'))\n",
    "\n",
    "check_basic_quality(logger, 's3a://short-interest-effect', '/data/test_table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pull Stock Info\n",
    "\n",
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass into `args` argument\n",
    "\n",
    "URL_NASDAQ = 'https://old.nasdaq.com/screening/companies-by-name.aspx?letter=0&exchange=nasdaq&render=download'\n",
    "URL_NYSE = 'https://old.nasdaq.com/screening/companies-by-name.aspx?letter=0&exchange=nyse&render=download'\n",
    "\n",
    "DB_HOST = ''\n",
    "# Table names: update to add '/' in the final code.\n",
    "TABLE_STOCK_INFO_NASDAQ = 'test_data/raw/stock_info_nasdaq'\n",
    "TABLE_STOCK_INFO_NYSE = 'test_data/raw/stock_info_nyse'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# The EMR cluster does not have pandas so we cannot use this.\n",
    "import pandas as pd\n",
    "\n",
    "def pull_stock_info(url, table_path):\n",
    "    try:\n",
    "        df = pd.read_csv(url)\n",
    "        df['MarketCap'] = df['MarketCap'].astype(str)\n",
    "        df['Sector'] = df['Sector'].astype(str)\n",
    "        df['industry'] = df['industry'].astype(str)\n",
    "        spark.createDataFrame(df) \\\n",
    "            .withColumnRenamed('Summary Quote', 'SummaryQuote') \\\n",
    "            .withColumnRenamed('Unnamed: 8', '_c8') \\\n",
    "            .drop('_c8') \\\n",
    "            .write.mode('overwrite').parquet(table_path)\n",
    "        logger.warn(\"Stored data from {} to {}\".format(url, table_path))\n",
    "    except IOError as e:\n",
    "        logger.warn(\"Failed to connect to {}. We will use existing stock info data if they have been created.\".format(url))\n",
    "        \n",
    "    \n",
    "pull_stock_info(URL_NASDAQ, DB_HOST+TABLE_STOCK_INFO_NASDAQ)\n",
    "pull_stock_info(URL_NYSE, DB_HOST+TABLE_STOCK_INFO_NYSE)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# On the EMR cluster, this code returns an error:\n",
    "# \"AttributeError: 'RDD' object has no attribute '_get_object_id'\\n\"\n",
    "# quite likely due to loading CSV from string: spark.read.csv(data, header=True)\n",
    "\n",
    "def pull_stock_info(url, table_path):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200 or response.status_code == 201:\n",
    "        content = response.content.decode('utf-8')\n",
    "        data = spark.sparkContext.parallelize(content.splitlines())\n",
    "        logger.warn(\"data is {}\".format(data))\n",
    "        df = spark.read.csv(data, header=True) \\\n",
    "            .withColumnRenamed('Summary Quote', 'SummaryQuote') \\\n",
    "            .drop('_c8') \\\n",
    "            .write.mode('overwrite').parquet(table_path)\n",
    "        logger.warn(\"Stored data from {} to {}\".format(url, table_path))\n",
    "    else:\n",
    "        logger.warn(\"Failed to connect to {}. We will use existing stock info data if they have been created.\".format(url))\n",
    "        \n",
    "    \n",
    "pull_stock_info(URL_NASDAQ, DB_HOST+TABLE_STOCK_INFO_NASDAQ)\n",
    "pull_stock_info(URL_NYSE, DB_HOST+TABLE_STOCK_INFO_NYSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARN:root:Stored data from https://old.nasdaq.com/screening/companies-by-name.aspx?letter=0&exchange=nasdaq&render=download to test_data/raw/stock_info_nasdaq\n",
      "WARN:root:Stored data from https://old.nasdaq.com/screening/companies-by-name.aspx?letter=0&exchange=nyse&render=download to test_data/raw/stock_info_nyse\n"
     ]
    }
   ],
   "source": [
    "def pull_stock_info(url, db_host, table_path):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200 or response.status_code == 201:\n",
    "        content = response.content.decode('utf-8')\n",
    "        content = content.replace('Summary Quote', 'SummaryQuote')\n",
    "        delete_path(spark, db_host, table_path)\n",
    "        df = spark.createDataFrame([[content]], ['info_csv'])\n",
    "        df.rdd.map(lambda x: x['info_csv'].replace(\"[\",\"\").replace(\"]\", \"\")).saveAsTextFile(db_host+table_path)\n",
    "        logger.warn(\"Stored data from {} to {}\".format(url, db_host+table_path))\n",
    "    else:\n",
    "        logger.warn(\"Failed to connect to {}. We will use existing stock info data if they have been created.\".format(url))\n",
    "        \n",
    "    \n",
    "pull_stock_info(URL_NASDAQ, DB_HOST, TABLE_STOCK_INFO_NASDAQ)\n",
    "pull_stock_info(URL_NYSE, DB_HOST, TABLE_STOCK_INFO_NYSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Name</th>\n",
       "      <th>LastSale</th>\n",
       "      <th>MarketCap</th>\n",
       "      <th>IPOyear</th>\n",
       "      <th>Sector</th>\n",
       "      <th>industry</th>\n",
       "      <th>SummaryQuote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3583</td>\n",
       "      <td>3583</td>\n",
       "      <td>3583</td>\n",
       "      <td>3583</td>\n",
       "      <td>3583</td>\n",
       "      <td>3583</td>\n",
       "      <td>3583</td>\n",
       "      <td>3583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3583</td>\n",
       "      <td>3153</td>\n",
       "      <td>2855</td>\n",
       "      <td>2828</td>\n",
       "      <td>44</td>\n",
       "      <td>13</td>\n",
       "      <td>128</td>\n",
       "      <td>3583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>SOHOB</td>\n",
       "      <td>Credit Suisse AG</td>\n",
       "      <td>25.75</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>n/a</td>\n",
       "      <td>https://old.nasdaq.com/symbol/oxbrw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>310</td>\n",
       "      <td>1891</td>\n",
       "      <td>782</td>\n",
       "      <td>524</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Symbol              Name LastSale MarketCap IPOyear       Sector  \\\n",
       "count    3583              3583     3583      3583    3583         3583   \n",
       "unique   3583              3153     2855      2828      44           13   \n",
       "top     SOHOB  Credit Suisse AG    25.75       n/a     n/a  Health Care   \n",
       "freq        1                10        7       310    1891          782   \n",
       "\n",
       "       industry                         SummaryQuote  \n",
       "count      3583                                 3583  \n",
       "unique      128                                 3583  \n",
       "top         n/a  https://old.nasdaq.com/symbol/oxbrw  \n",
       "freq        524                                    1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.csv(DB_HOST+TABLE_STOCK_INFO_NASDAQ, header=True, inferSchema=True) \\\n",
    "               .drop('_c8').toPandas()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Name</th>\n",
       "      <th>LastSale</th>\n",
       "      <th>MarketCap</th>\n",
       "      <th>IPOyear</th>\n",
       "      <th>Sector</th>\n",
       "      <th>industry</th>\n",
       "      <th>SummaryQuote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3092</td>\n",
       "      <td>3092</td>\n",
       "      <td>3092</td>\n",
       "      <td>3092</td>\n",
       "      <td>3092</td>\n",
       "      <td>3092</td>\n",
       "      <td>3092</td>\n",
       "      <td>3092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3092</td>\n",
       "      <td>2438</td>\n",
       "      <td>2417</td>\n",
       "      <td>1922</td>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>133</td>\n",
       "      <td>3092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>CNR</td>\n",
       "      <td>Bank of America Corporation</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>https://old.nasdaq.com/symbol/rio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>105</td>\n",
       "      <td>702</td>\n",
       "      <td>1659</td>\n",
       "      <td>1011</td>\n",
       "      <td>1011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Symbol                         Name LastSale MarketCap IPOyear Sector  \\\n",
       "count    3092                         3092     3092      3092    3092   3092   \n",
       "unique   3092                         2438     2417      1922      36     13   \n",
       "top       CNR  Bank of America Corporation      n/a       n/a     n/a    n/a   \n",
       "freq        1                           14      105       702    1659   1011   \n",
       "\n",
       "       industry                       SummaryQuote  \n",
       "count      3092                               3092  \n",
       "unique      133                               3092  \n",
       "top         n/a  https://old.nasdaq.com/symbol/rio  \n",
       "freq       1011                                  1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.csv(DB_HOST+TABLE_STOCK_INFO_NYSE,\n",
    "                    header=True, ignoreLeadingWhiteSpace=True, inferSchema=True) \\\n",
    "               .drop('_c8').toPandas()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Name</th>\n",
       "      <th>LastSale</th>\n",
       "      <th>MarketCap</th>\n",
       "      <th>IPOyear</th>\n",
       "      <th>Sector</th>\n",
       "      <th>industry</th>\n",
       "      <th>SummaryQuote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DDD</td>\n",
       "      <td>3D Systems Corporation</td>\n",
       "      <td>11.38</td>\n",
       "      <td>$1.35B</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Computer Software: Prepackaged Software</td>\n",
       "      <td>https://old.nasdaq.com/symbol/ddd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MMM</td>\n",
       "      <td>3M Company</td>\n",
       "      <td>178.15</td>\n",
       "      <td>$102.45B</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Medical/Dental Instruments</td>\n",
       "      <td>https://old.nasdaq.com/symbol/mmm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WBAI</td>\n",
       "      <td>500.com Limited</td>\n",
       "      <td>7.41</td>\n",
       "      <td>$318.62M</td>\n",
       "      <td>2013</td>\n",
       "      <td>Consumer Services</td>\n",
       "      <td>Services-Misc. Amusement &amp; Recreation</td>\n",
       "      <td>https://old.nasdaq.com/symbol/wbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WUBA</td>\n",
       "      <td>58.com Inc.</td>\n",
       "      <td>62.59</td>\n",
       "      <td>$9.36B</td>\n",
       "      <td>2013</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Computer Software: Programming, Data Processing</td>\n",
       "      <td>https://old.nasdaq.com/symbol/wuba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EGHT</td>\n",
       "      <td>8x8 Inc</td>\n",
       "      <td>19.34</td>\n",
       "      <td>$1.94B</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Technology</td>\n",
       "      <td>EDP Services</td>\n",
       "      <td>https://old.nasdaq.com/symbol/eght</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol                    Name LastSale MarketCap IPOyear  \\\n",
       "0    DDD  3D Systems Corporation    11.38    $1.35B     n/a   \n",
       "1    MMM              3M Company   178.15  $102.45B     n/a   \n",
       "2   WBAI         500.com Limited     7.41  $318.62M    2013   \n",
       "3   WUBA             58.com Inc.    62.59    $9.36B    2013   \n",
       "4   EGHT                 8x8 Inc    19.34    $1.94B     n/a   \n",
       "\n",
       "              Sector                                         industry  \\\n",
       "0         Technology          Computer Software: Prepackaged Software   \n",
       "1        Health Care                       Medical/Dental Instruments   \n",
       "2  Consumer Services            Services-Misc. Amusement & Recreation   \n",
       "3         Technology  Computer Software: Programming, Data Processing   \n",
       "4         Technology                                     EDP Services   \n",
       "\n",
       "                         SummaryQuote  \n",
       "0   https://old.nasdaq.com/symbol/ddd  \n",
       "1   https://old.nasdaq.com/symbol/mmm  \n",
       "2  https://old.nasdaq.com/symbol/wbai  \n",
       "3  https://old.nasdaq.com/symbol/wuba  \n",
       "4  https://old.nasdaq.com/symbol/eght  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality-check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARN:root:(SUCCESS) Table test_data/raw/stock_info_nasdaq has 3583 rows.\n",
      "WARN:root:(SUCCESS) Table test_data/raw/stock_info_nyse has 3092 rows.\n"
     ]
    }
   ],
   "source": [
    "check_basic_quality(logger, DB_HOST, TABLE_STOCK_INFO_NASDAQ, table_type='csv')\n",
    "check_basic_quality(logger, DB_HOST, TABLE_STOCK_INFO_NYSE, table_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pull Short Interest\n",
    "\n",
    "#### Parallelize based on stocks or parallelize based on returned data points?\n",
    "\n",
    "At the time of writing (2020-01-15), we have 3582 stocks from NASDAQ and 3092 stocks from NYSE. The earliest date is 2013-04-01, which accounts for nearly 1700 data points (261 working days each year).\n",
    "\n",
    "For each stock, we will need to connect to an external API (Quandl or QuoteMedia). This will take more of the processing time rather than data processing. Therefore, we parallelize based on the stocks rather than returned data points. This way, multiple Spark nodes can connect to different URLs and pull the data. The downside is, obviously, for each node we will have to iteratively process the data, but this is still faster as there are fewer data points than the stocks, at least until several years in the future (There might be a solution that allows each spark node to parallelize...).\n",
    "\n",
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exchange_map = {\n",
    "#     'nasdaq': 'FNSQ',\n",
    "#     'nyse': 'FNYX'\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2020-01-24', 626537.0, 0.0, 1618628.0]\n",
      "['Date', 'ShortVolume', 'ShortExemptVolume', 'TotalVolume']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'Date': '2020-01-24',\n",
       "  'ShortVolume': 626537.0,\n",
       "  'ShortExemptVolume': 0.0,\n",
       "  'TotalVolume': 1618628.0},\n",
       " {'Date': '2020-01-23',\n",
       "  'ShortVolume': 351564.0,\n",
       "  'ShortExemptVolume': 0.0,\n",
       "  'TotalVolume': 998258.0}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://www.quandl.com/api/v3/datasets/FINRA/FNYX_FB?api_key={}\".format(config['Quandl']['API_KEY'])\n",
    "result = requests.get(url).json()\n",
    "print(result['dataset']['data'][0])\n",
    "print(result['dataset']['column_names'])\n",
    "col_names = [result['dataset']['column_names']] * len(result['dataset']['data'])\n",
    "newdata = []\n",
    "for i, cols in enumerate(col_names):\n",
    "    newdata.append(dict(zip(cols, result['dataset']['data'][i])))\n",
    "newdata[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write to single tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass into `args` argument\n",
    "\n",
    "START_DATE = config['App']['START_DATE']\n",
    "QUANDL_API_KEY = config['Quandl']['API_KEY']\n",
    "YESTERDAY_DATE = '2019-12-16'\n",
    "LIMIT = 1\n",
    "# STOCKS = ['FB', 'GOOG', 'AMZN', 'TRMT', 'TSLA', 'MCD', 'NFLX']\n",
    "STOCKS = []\n",
    "AWS_ACCESS_KEY_ID = config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "AWS_SECRET_ACCESS_KEY = config['AWS']['AWS_SECRET_ACCESS_KEY']\n",
    "DB_HOST = ''\n",
    "\n",
    "# Table names: update to add '/' in the final code.\n",
    "TABLE_STOCK_INFO_NASDAQ = 'test_data/raw/stock_info_nasdaq'\n",
    "TABLE_STOCK_INFO_NYSE = 'test_data/raw/stock_info_nyse'\n",
    "TABLE_SHORT_INTERESTS_NASDAQ = 'test_data/raw/short_interests_nasdaq' \n",
    "TABLE_SHORT_INTERESTS_NYSE = 'test_data/raw/short_interests_nyse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARN:root:1/1 - total rows in this batch: 0\n",
      "WARN:root:done!\n",
      "WARN:root:1/1 - total rows in this batch: 0\n",
      "WARN:root:done!\n"
     ]
    }
   ],
   "source": [
    "# %%timeit -n 1 -r 1\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "def a_before_b(a, b):\n",
    "    date_format = \"%Y-%m-%d\"\n",
    "\n",
    "    # create datetime objects from the strings\n",
    "    da = datetime.strptime(a, date_format)\n",
    "    db = datetime.strptime(b, date_format)\n",
    "\n",
    "    if da < db:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def convert_data(olddata, symbol, url):\n",
    "    col_names = olddata['dataset']['column_names']\n",
    "    col_names.append('Symbol')\n",
    "    col_names.append('SourceURL')\n",
    "    col_names_multiplied = [col_names] * len(olddata['dataset']['data'])\n",
    "    newdata = []\n",
    "    for i, cols in enumerate(col_names_multiplied):\n",
    "        datum = olddata['dataset']['data'][i]\n",
    "        datum.append(symbol)\n",
    "        datum.append(url)\n",
    "        newdata.append(dict(zip(cols, datum)))\n",
    "    return newdata\n",
    "\n",
    "\n",
    "def pull_short_interests(exchange, host, info_table_path, short_interests_table_path, log_every_n=100):\n",
    "        \n",
    "    def pull_exchange_short_interests_by_symbol(symbol, start_date, end_date):\n",
    "        \"\"\"\n",
    "        Return:\n",
    "            list of dicts [{'colname': value, ...}, ...]\n",
    "        \"\"\"\n",
    "        url = 'https://www.quandl.com/api/v3/datasets/FINRA/'+exchange+'_{}?start_date='+start_date+'&end_date='+end_date+'&api_key='+QUANDL_API_KEY\n",
    "        url = url.format(symbol)\n",
    "        response = requests.get(url)\n",
    "        newdata = []\n",
    "        if response.status_code in [200, 201]:\n",
    "            newdata = convert_data(response.json(), symbol, url)\n",
    "        return newdata\n",
    "\n",
    "    # Prepare list of stocks\n",
    "    if STOCKS is not None and len(STOCKS) > 0:\n",
    "        rdd1 = spark.sparkContext.parallelize(STOCKS)\n",
    "        row_rdd = rdd1.map(lambda x: Row(x))\n",
    "        df = spark.createDataFrame(row_rdd,['Symbol'])\n",
    "    else:\n",
    "        df = spark.read.csv(host+info_table_path, header=True)\n",
    "        if LIMIT is not None:\n",
    "            df = df.limit(LIMIT)\n",
    "    symbols = df.select('Symbol').rdd.map(lambda r: r['Symbol']).collect()\n",
    "    \n",
    "    table_exists = spark_table_exists(host, short_interests_table_path)\n",
    "    if table_exists:\n",
    "        short_sdf = spark.read.csv(host+short_interests_table_path, header=True)\n",
    "        \n",
    "    total_rows = 0\n",
    "    for i, symbol in enumerate(symbols):\n",
    "        if table_exists:\n",
    "            # Get the last date of a stock. If this last date >= YESTERDAY_DATE, don't do anything.\n",
    "            dates = short_sdf.select('Date').where((short_sdf.Symbol == F.lit(symbol))).orderBy(F.desc('Date')).limit(1) \\\n",
    "                .rdd.map(lambda r: r['Date']).collect()\n",
    "            if len(dates) > 0:\n",
    "                if a_before_b(dates[0], YESTERDAY_DATE):\n",
    "                    data = pull_exchange_short_interests_by_symbol(symbol, dates[0], YESTERDAY_DATE)\n",
    "                else:\n",
    "                    data = []\n",
    "            else:\n",
    "                data = pull_exchange_short_interests_by_symbol(symbol, START_DATE, YESTERDAY_DATE)\n",
    "        else:\n",
    "            data = pull_exchange_short_interests_by_symbol(symbol, START_DATE, YESTERDAY_DATE)\n",
    "        total_rows += len(data)\n",
    "        if (i%log_every_n == 0):\n",
    "            logger.warn(\"{}/{} - total rows in this batch: {}\".format(i+1, len(symbols), total_rows))\n",
    "        \n",
    "        if len(data) > 0:\n",
    "            short_sdf = spark.createDataFrame(data)\n",
    "            short_sdf.write.mode('append').format('csv').save(host+short_interests_table_path, header=True)\n",
    "    logger.warn(\"done!\")\n",
    "\n",
    "pull_short_interests('FNSQ', DB_HOST, TABLE_STOCK_INFO_NASDAQ, TABLE_SHORT_INTERESTS_NASDAQ)\n",
    "pull_short_interests('FNYX', DB_HOST, TABLE_STOCK_INFO_NYSE, TABLE_SHORT_INTERESTS_NYSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "https://www.quandl.com/api/v3/datasets/FINRA/FNSQ_AGNC?start_date=2013-04-01&end_date=2019-12-12&api_key=W_R9Vr9k9D5MDsXKRY3e\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ShortExemptVolume</th>\n",
       "      <th>ShortVolume</th>\n",
       "      <th>SourceURL</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>TotalVolume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-02-05</td>\n",
       "      <td>2779.0</td>\n",
       "      <td>1370782.0</td>\n",
       "      <td>https://www.quandl.com/api/v3/datasets/FINRA/F...</td>\n",
       "      <td>AGNC</td>\n",
       "      <td>3674388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-02-04</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1785639.0</td>\n",
       "      <td>https://www.quandl.com/api/v3/datasets/FINRA/F...</td>\n",
       "      <td>AGNC</td>\n",
       "      <td>5315228.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-02-03</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1190818.0</td>\n",
       "      <td>https://www.quandl.com/api/v3/datasets/FINRA/F...</td>\n",
       "      <td>AGNC</td>\n",
       "      <td>4074361.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-31</td>\n",
       "      <td>123.0</td>\n",
       "      <td>672564.0</td>\n",
       "      <td>https://www.quandl.com/api/v3/datasets/FINRA/F...</td>\n",
       "      <td>AGNC</td>\n",
       "      <td>1936362.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-01-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>492736.0</td>\n",
       "      <td>https://www.quandl.com/api/v3/datasets/FINRA/F...</td>\n",
       "      <td>AGNC</td>\n",
       "      <td>1778221.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date ShortExemptVolume ShortVolume  \\\n",
       "0  2014-02-05            2779.0   1370782.0   \n",
       "1  2014-02-04             100.0   1785639.0   \n",
       "2  2014-02-03             400.0   1190818.0   \n",
       "3  2014-01-31             123.0    672564.0   \n",
       "4  2014-01-30               0.0    492736.0   \n",
       "\n",
       "                                           SourceURL Symbol TotalVolume  \n",
       "0  https://www.quandl.com/api/v3/datasets/FINRA/F...   AGNC   3674388.0  \n",
       "1  https://www.quandl.com/api/v3/datasets/FINRA/F...   AGNC   5315228.0  \n",
       "2  https://www.quandl.com/api/v3/datasets/FINRA/F...   AGNC   4074361.0  \n",
       "3  https://www.quandl.com/api/v3/datasets/FINRA/F...   AGNC   1936362.0  \n",
       "4  https://www.quandl.com/api/v3/datasets/FINRA/F...   AGNC   1778221.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf = spark.read.csv(DB_HOST+TABLE_SHORT_INTERESTS_NASDAQ, header=True).limit(5).dropDuplicates(['Date', 'Symbol'])\n",
    "sdf = sdf.orderBy(sdf.Date.desc())\n",
    "print(sdf.count())\n",
    "df = sdf.toPandas()\n",
    "print(df['SourceURL'][0])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ShortExemptVolume</th>\n",
       "      <th>ShortVolume</th>\n",
       "      <th>SourceURL</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>TotalVolume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-01-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>492736.0</td>\n",
       "      <td>https://www.quandl.com/api/v3/datasets/FINRA/F...</td>\n",
       "      <td>AGNC</td>\n",
       "      <td>1778221.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-31</td>\n",
       "      <td>123.0</td>\n",
       "      <td>672564.0</td>\n",
       "      <td>https://www.quandl.com/api/v3/datasets/FINRA/F...</td>\n",
       "      <td>AGNC</td>\n",
       "      <td>1936362.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-02-03</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1190818.0</td>\n",
       "      <td>https://www.quandl.com/api/v3/datasets/FINRA/F...</td>\n",
       "      <td>AGNC</td>\n",
       "      <td>4074361.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-02-04</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1785639.0</td>\n",
       "      <td>https://www.quandl.com/api/v3/datasets/FINRA/F...</td>\n",
       "      <td>AGNC</td>\n",
       "      <td>5315228.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-02-05</td>\n",
       "      <td>2779.0</td>\n",
       "      <td>1370782.0</td>\n",
       "      <td>https://www.quandl.com/api/v3/datasets/FINRA/F...</td>\n",
       "      <td>AGNC</td>\n",
       "      <td>3674388.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date ShortExemptVolume ShortVolume  \\\n",
       "4  2014-01-30               0.0    492736.0   \n",
       "3  2014-01-31             123.0    672564.0   \n",
       "2  2014-02-03             400.0   1190818.0   \n",
       "1  2014-02-04             100.0   1785639.0   \n",
       "0  2014-02-05            2779.0   1370782.0   \n",
       "\n",
       "                                           SourceURL Symbol TotalVolume  \n",
       "4  https://www.quandl.com/api/v3/datasets/FINRA/F...   AGNC   1778221.0  \n",
       "3  https://www.quandl.com/api/v3/datasets/FINRA/F...   AGNC   1936362.0  \n",
       "2  https://www.quandl.com/api/v3/datasets/FINRA/F...   AGNC   4074361.0  \n",
       "1  https://www.quandl.com/api/v3/datasets/FINRA/F...   AGNC   5315228.0  \n",
       "0  https://www.quandl.com/api/v3/datasets/FINRA/F...   AGNC   3674388.0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['Date', 'Symbol'], ascending=True).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality-check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass into `args` argument\n",
    "\n",
    "STOCKS = ['FB', 'GOOG', 'AMZN', 'TRMT', 'TSLA', 'MCD', 'NFLX']\n",
    "DB_HOST = ''\n",
    "\n",
    "# Table names: update to add '/' in the final code.\n",
    "TABLE_STOCK_INFO_NASDAQ = 'test_data/raw/stock_info_nasdaq'\n",
    "TABLE_STOCK_INFO_NYSE = 'test_data/raw/stock_info_nyse'\n",
    "TABLE_SHORT_INTERESTS_NASDAQ = 'test_data/raw/short_interests_nasdaq' \n",
    "TABLE_SHORT_INTERESTS_NYSE = 'test_data/raw/short_interests_nyse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARN:root:(SUCCESS) Table test_data/raw/short_interests_nasdaq has 528633 rows.\n",
      "WARN:root:(SUCCESS) Table test_data/raw/short_interests_nyse has 483503 rows.\n"
     ]
    }
   ],
   "source": [
    "if STOCKS is None or len(STOCKS) == 0:\n",
    "    check_basic_quality(logger, DB_HOST, TABLE_STOCK_INFO_NASDAQ, table_type='csv')\n",
    "    check_basic_quality(logger, DB_HOST, TABLE_STOCK_INFO_NYSE, table_type='csv')\n",
    "check_basic_quality(logger, DB_HOST, TABLE_SHORT_INTERESTS_NASDAQ)\n",
    "check_basic_quality(logger, DB_HOST, TABLE_SHORT_INTERESTS_NYSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pull Stock Prices\n",
    "\n",
    "### Code (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass into `args` argument\n",
    "\n",
    "START_DATE = config['App']['START_DATE']\n",
    "QUANDL_API_KEY = config['Quandl']['API_KEY']\n",
    "YESTERDAY_DATE = '2019-12-12'\n",
    "LIMIT = 100\n",
    "STOCKS = []\n",
    "AWS_ACCESS_KEY_ID = config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "AWS_SECRET_ACCESS_KEY = config['AWS']['AWS_SECRET_ACCESS_KEY']\n",
    "DB_HOST = ''\n",
    "\n",
    "# Table names: update to add '/' in the final code.\n",
    "TABLE_STOCK_INFO_NASDAQ = 'test_data/raw/stock_info_nasdaq'\n",
    "TABLE_STOCK_INFO_NYSE = 'test_data/raw/stock_info_nyse'\n",
    "TABLE_STOCK_PRICES = 'test_data/raw/prices'\n",
    "\n",
    "URL = \"\"\"http://app.quotemedia.com/quotetools/getHistoryDownload.csv?&webmasterId=501&startDay={sd}&startMonth={sm}&startYear={sy}&endDay={ed}&endMonth={em}&endYear={ey}&isRanged=true&symbol={sym}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARN:root:HELLO1\n",
      "WARN:root:HELLO2\n",
      "WARN:root:Appending to table test_data/raw/prices\n",
      "WARN:root:    Creating temporary table test_data/raw/prices-temp\n",
      "WARN:root:    done! Now appending to table test_data/raw/prices\n",
      "WARN:root:done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3min 3s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "\n",
    "START_DAY = START_DATE.split('-')[2]\n",
    "# In QuoteMedia, months start from 0, so we adjust this variable.\n",
    "START_MONTH = int(START_DATE.split('-')[1]) - 1\n",
    "START_YEAR = START_DATE.split('-')[0]\n",
    "\n",
    "YST_DAY = YESTERDAY_DATE.split('-')[2]\n",
    "# In QuoteMedia, months start from 0, so we adjust this variable.\n",
    "YST_MONTH = int(YESTERDAY_DATE.split('-')[1]) - 1\n",
    "YST_YEAR = YESTERDAY_DATE.split('-')[0]\n",
    "\n",
    "create_table = not(spark_table_exists(DB_HOST, TABLE_STOCK_PRICES))\n",
    "def pull_prices_by_symbol(symbol):\n",
    "    \"\"\"\n",
    "    Return:\n",
    "        list of dicts [{'colname': value, ...}, ...]\n",
    "    \"\"\"\n",
    "    if create_table == True:\n",
    "        # If table does not exist, pull all data.\n",
    "        url = URL.format(sd=START_DAY, sm=START_MONTH, sy=START_YEAR,\n",
    "                         ed=YST_DAY, em=YST_MONTH, ey=YST_YEAR,\n",
    "                         sym=symbol)\n",
    "    else:\n",
    "        # If table had existed, pull yesterday's data.\n",
    "        url = URL.format(sd=YST_DAY, sm=YST_MONTH, sy=YST_YEAR,\n",
    "                         ed=YST_DAY, em=YST_MONTH, ey=YST_YEAR,\n",
    "                         sym=symbol)\n",
    "        \n",
    "    # Code for always overwrite without temp table\n",
    "#     url = URL.format(sd=START_DAY, sm=START_MONTH, sy=START_YEAR,\n",
    "#                      ed=YST_DAY, em=YST_MONTH, ey=YST_YEAR,\n",
    "#                      sym=symbol)\n",
    "\n",
    "    response = requests.get(url)\n",
    "    newdata = \"\"\n",
    "    if response.status_code in [200, 201]:\n",
    "        newdata = response.content.decode('utf-8')\n",
    "        newdata = newdata.replace('\\n', ','+symbol+'\\n')\n",
    "        newdata = newdata.replace('tradevol,'+symbol+'\\n', 'tradevol,symbol\\n')\n",
    "    return newdata\n",
    "\n",
    "schema = T.StringType()\n",
    "udf_pull_prices = F.udf(pull_prices_by_symbol, schema)\n",
    "    \n",
    "# Prepare list of stocks\n",
    "if STOCKS is not None and len(STOCKS) > 0:\n",
    "    rdd1 = spark.sparkContext.parallelize(STOCKS)\n",
    "    row_rdd = rdd1.map(lambda x: Row(x))\n",
    "    df = spark.createDataFrame(row_rdd,['Symbol'])\n",
    "else:\n",
    "    df = spark.read.csv([DB_HOST+TABLE_STOCK_INFO_NASDAQ,\n",
    "                        DB_HOST+TABLE_STOCK_INFO_NYSE], header=True) \\\n",
    "         .select('Symbol').dropDuplicates()\n",
    "    if LIMIT is not None:\n",
    "        df = df.limit(LIMIT)\n",
    "\n",
    "df = df.withColumn('prices_csv', udf_pull_prices('Symbol'))\n",
    "\n",
    "df = df.select('prices_csv').where(df['prices_csv'] != '')\n",
    "\n",
    "table_name = DB_HOST+TABLE_STOCK_PRICES\n",
    "mode = 'overwrite'\n",
    "if create_table:\n",
    "    logger.warn(\"Creating table {}\".format(table_name))    \n",
    "else:\n",
    "    logger.warn(\"Appending to table {}\".format(table_name))\n",
    "    mode = 'append'\n",
    "\n",
    "# Repartition here is important so we may end up with multiple CSV-like files.\n",
    "# Without repartition, the headers are going to be written multiple times\n",
    "# in a single csv file.\n",
    "tempdir = DB_HOST+TABLE_STOCK_PRICES+'-temp'\n",
    "logger.warn(\"    Creating temporary table {}\".format(tempdir))\n",
    "\n",
    "numrows = df.count()\n",
    "df \\\n",
    "    .repartition(numrows).write.mode('overwrite') \\\n",
    "    .csv(tempdir, header=False, quote=\" \")\n",
    "\n",
    "\n",
    "if create_table:\n",
    "    logger.warn(\"    done! Now creating table {}\".format(table_name))\n",
    "else:\n",
    "    logger.warn(\"    done! Now appending to table {}\".format(table_name))\n",
    "\n",
    "spark.read.csv(tempdir, header=True, ignoreLeadingWhiteSpace=True, inferSchema=True) \\\n",
    ".write.mode(mode).csv(table_name, header=True)\n",
    "# .write.mode(mode).parquet(DB_HOST+TABLE_STOCK_PRICES)\n",
    "\n",
    "\n",
    "logger.warn(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %%timeit -n 1 -r 1\n",
    "\n",
    "# import csv\n",
    "\n",
    "# log_every_n = 100\n",
    "\n",
    "# def pull_prices_by_symbol(symbol, start_date, end_date):\n",
    "#     \"\"\"\n",
    "#     Return:\n",
    "#         list of dicts [{'colname': value, ...}, ...]\n",
    "#     \"\"\"\n",
    "    \n",
    "#     sday = start_date.split('-')[2]\n",
    "#     # In QuoteMedia, months start from 0, so we adjust this variable.\n",
    "#     smonth = int(start_date.split('-')[1]) - 1\n",
    "#     syear = start_date.split('-')[0]\n",
    "\n",
    "#     eday = end_date.split('-')[2]\n",
    "#     # In QuoteMedia, months start from 0, so we adjust this variable.\n",
    "#     emonth = int(end_date.split('-')[1]) - 1\n",
    "#     eyear = end_date.split('-')[0]\n",
    "\n",
    "#     url = URL.format(sd=sday, sm=smonth, sy=syear,\n",
    "#                      ed=eday, em=emonth, ey=eyear,\n",
    "#                      sym=symbol)\n",
    "    \n",
    "#     response = requests.get(url)\n",
    "#     newdata = \"\"\n",
    "#     if response.status_code in [200, 201]:\n",
    "#         newdata = response.content.decode('utf-8')\n",
    "#         newdata = newdata.replace('\\n', ','+symbol+'\\n')\n",
    "#         newdata = newdata.replace('tradevol,'+symbol+'\\n', 'tradevol,symbol\\n')\n",
    "        \n",
    "#     reader = csv.reader(scsv.split('\\n'), delimiter=',')\n",
    "#     for row in reader:\n",
    "#         print('\\t'.join(row))\n",
    "        \n",
    "#     return newdata\n",
    "\n",
    "    \n",
    "# # Prepare list of stocks\n",
    "# if STOCKS is not None and len(STOCKS) > 0:\n",
    "#     rdd1 = spark.sparkContext.parallelize(STOCKS)\n",
    "#     row_rdd = rdd1.map(lambda x: Row(x))\n",
    "#     df = spark.createDataFrame(row_rdd,['Symbol'])\n",
    "# else:\n",
    "#     df = spark.read.csv([DB_HOST+TABLE_STOCK_INFO_NASDAQ,\n",
    "#                          DB_HOST+TABLE_STOCK_INFO_NYSE], header=True) \\\n",
    "#          .select('Symbol').dropDuplicates()\n",
    "#     if LIMIT is not None:\n",
    "#         df = df.limit(LIMIT)\n",
    "\n",
    "# symbols = df.select('Symbol').rdd.map(lambda r: r['Symbol']).collect()\n",
    "    \n",
    "# table_exists = spark_table_exists(DB_HOST, TABLE_STOCK_PRICES)\n",
    "# if table_exists:\n",
    "#     price_sdf = spark.read.csv(DB_HOST+TABLE_STOCK_PRICES, header=True)\n",
    "\n",
    "# total_rows = 0\n",
    "# for i, symbol in enumerate(symbols):\n",
    "#     if table_exists:\n",
    "#         # Get the last date of a stock. If this last date >= YESTERDAY_DATE, don't do anything.\n",
    "#         dates = price_sdf.select('date').where((price_sdf.symbol == F.lit(symbol))).orderBy(F.desc('date')).limit(1) \\\n",
    "#             .rdd.map(lambda r: r['date']).collect()\n",
    "#         if len(dates) > 0:\n",
    "#             strdata = pull_prices_by_symbol(symbol, dates[0], YESTERDAY_DATE)\n",
    "#         else:\n",
    "#             strdata = pull_prices_by_symbol(symbol, START_DATE, YESTERDAY_DATE)\n",
    "#     else:\n",
    "#         strdata = pull_prices_by_symbol(symbol, START_DATE, YESTERDAY_DATE)\n",
    "#     if strdata != '':\n",
    "#         sdf = spark.sparkContext.parallelize(strdata).toDF()\n",
    "#         sdf.toD\n",
    "# #     total_rows += len(data)\n",
    "# #     if (i%log_every_n == 0):\n",
    "# #         logger.warn(\"{}/{} - total rows in this batch: {}\".format(i, len(symbols), total_rows))\n",
    "\n",
    "# #     if len(data) > 0:\n",
    "# #         price_sdf = spark.createDataFrame(data)\n",
    "# #         price_sdf.write.mode('append').format('csv').save(DB_HOST+TABLE_STOCK_PRICES, header=True)\n",
    "\n",
    "\n",
    "# logger.warn(\"done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 93 entries, 0 to 92\n",
      "Data columns (total 12 columns):\n",
      "date        93 non-null object\n",
      "open        93 non-null object\n",
      "high        93 non-null object\n",
      "low         93 non-null object\n",
      "close       93 non-null object\n",
      "volume      93 non-null object\n",
      "changed     93 non-null object\n",
      "changep     93 non-null object\n",
      "adjclose    93 non-null object\n",
      "tradeval    93 non-null object\n",
      "tradevol    93 non-null object\n",
      "symbol      93 non-null object\n",
      "dtypes: object(12)\n",
      "memory usage: 8.8+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>changed</th>\n",
       "      <th>changep</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>tradeval</th>\n",
       "      <th>tradevol</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-12-12</td>\n",
       "      <td>272.09</td>\n",
       "      <td>272.575</td>\n",
       "      <td>270.20</td>\n",
       "      <td>270.29</td>\n",
       "      <td>1779499</td>\n",
       "      <td>-1.86</td>\n",
       "      <td>-0.68%</td>\n",
       "      <td>270.29</td>\n",
       "      <td>482215933.19</td>\n",
       "      <td>22880</td>\n",
       "      <td>SPGI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-12-12</td>\n",
       "      <td>166.73</td>\n",
       "      <td>170.85</td>\n",
       "      <td>166.325</td>\n",
       "      <td>168.56</td>\n",
       "      <td>2872410</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-0.11%</td>\n",
       "      <td>168.56</td>\n",
       "      <td>484265329.49</td>\n",
       "      <td>30864</td>\n",
       "      <td>MMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-12-12</td>\n",
       "      <td>116.56</td>\n",
       "      <td>117.27</td>\n",
       "      <td>113.92</td>\n",
       "      <td>114.31</td>\n",
       "      <td>375268</td>\n",
       "      <td>-1.666</td>\n",
       "      <td>-1.44%</td>\n",
       "      <td>114.0482</td>\n",
       "      <td>43052432.92</td>\n",
       "      <td>8276</td>\n",
       "      <td>RGLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-12-12</td>\n",
       "      <td>91.41</td>\n",
       "      <td>91.41</td>\n",
       "      <td>90.91</td>\n",
       "      <td>91.08</td>\n",
       "      <td>2281518</td>\n",
       "      <td>-0.289</td>\n",
       "      <td>-0.32%</td>\n",
       "      <td>90.8252</td>\n",
       "      <td>207835625.98</td>\n",
       "      <td>10173</td>\n",
       "      <td>VCIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-12-12</td>\n",
       "      <td>109.60</td>\n",
       "      <td>112.84</td>\n",
       "      <td>109.15</td>\n",
       "      <td>112.47</td>\n",
       "      <td>1818087</td>\n",
       "      <td>2.97</td>\n",
       "      <td>2.71%</td>\n",
       "      <td>112.47</td>\n",
       "      <td>203237156.99</td>\n",
       "      <td>22552</td>\n",
       "      <td>ALXN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date    open     high      low   close   volume changed changep  \\\n",
       "0  2019-12-12  272.09  272.575   270.20  270.29  1779499   -1.86  -0.68%   \n",
       "1  2019-12-12  166.73   170.85  166.325  168.56  2872410   -0.18  -0.11%   \n",
       "2  2019-12-12  116.56   117.27   113.92  114.31   375268  -1.666  -1.44%   \n",
       "3  2019-12-12   91.41    91.41    90.91   91.08  2281518  -0.289  -0.32%   \n",
       "4  2019-12-12  109.60   112.84   109.15  112.47  1818087    2.97   2.71%   \n",
       "\n",
       "   adjclose      tradeval tradevol symbol  \n",
       "0    270.29  482215933.19    22880  SPGI   \n",
       "1    168.56  484265329.49    30864   MMM   \n",
       "2  114.0482   43052432.92     8276  RGLD   \n",
       "3   90.8252  207835625.98    10173  VCIT   \n",
       "4    112.47  203237156.99    22552  ALXN   "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_temp = spark.read.csv(DB_HOST+TABLE_STOCK_PRICES+'-temp', header=True, ignoreLeadingWhiteSpace=True, inferSchema=True).toPandas()\n",
    "print(pdf_temp.info())\n",
    "pdf_temp.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10549 entries, 0 to 10548\n",
      "Data columns (total 12 columns):\n",
      "date        10548 non-null datetime64[ns]\n",
      "open        10548 non-null object\n",
      "high        10548 non-null object\n",
      "low         10548 non-null object\n",
      "close       10548 non-null float64\n",
      "volume      10548 non-null float64\n",
      "changed     10548 non-null float64\n",
      "changep     10548 non-null object\n",
      "adjclose    10548 non-null float64\n",
      "tradeval    10548 non-null object\n",
      "tradevol    10548 non-null float64\n",
      "symbol      10548 non-null object\n",
      "dtypes: datetime64[ns](1), float64(5), object(6)\n",
      "memory usage: 989.0+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>changed</th>\n",
       "      <th>changep</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>tradeval</th>\n",
       "      <th>tradevol</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-04-19</td>\n",
       "      <td>25.62</td>\n",
       "      <td>25.96</td>\n",
       "      <td>25.33</td>\n",
       "      <td>25.73</td>\n",
       "      <td>20353547.0</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>25.7300</td>\n",
       "      <td>523595607.18</td>\n",
       "      <td>66068.0</td>\n",
       "      <td>FB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-04-22</td>\n",
       "      <td>99.35</td>\n",
       "      <td>99.66</td>\n",
       "      <td>98.38</td>\n",
       "      <td>99.32</td>\n",
       "      <td>5609009.0</td>\n",
       "      <td>-0.493</td>\n",
       "      <td>-0.60%</td>\n",
       "      <td>81.5900</td>\n",
       "      <td>555207178.14</td>\n",
       "      <td>32582.0</td>\n",
       "      <td>MCD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-04-26</td>\n",
       "      <td>100.83</td>\n",
       "      <td>100.99</td>\n",
       "      <td>100.40</td>\n",
       "      <td>100.89</td>\n",
       "      <td>3113532.0</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>-0.05%</td>\n",
       "      <td>82.8798</td>\n",
       "      <td>313733616.64</td>\n",
       "      <td>16412.0</td>\n",
       "      <td>MCD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-05-13</td>\n",
       "      <td>26.60</td>\n",
       "      <td>27.325</td>\n",
       "      <td>26.531</td>\n",
       "      <td>26.82</td>\n",
       "      <td>29009648.0</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.52%</td>\n",
       "      <td>26.8200</td>\n",
       "      <td>782579320.46</td>\n",
       "      <td>90803.0</td>\n",
       "      <td>FB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-07-10</td>\n",
       "      <td>291.41</td>\n",
       "      <td>293.34</td>\n",
       "      <td>289.40</td>\n",
       "      <td>292.33</td>\n",
       "      <td>1822877.0</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.27%</td>\n",
       "      <td>292.3300</td>\n",
       "      <td>531832345.31</td>\n",
       "      <td>11812.0</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date    open    high     low   close      volume  changed changep  \\\n",
       "0 2013-04-19   25.62   25.96   25.33   25.73  20353547.0    0.040   0.16%   \n",
       "1 2013-04-22   99.35   99.66   98.38   99.32   5609009.0   -0.493  -0.60%   \n",
       "2 2013-04-26  100.83  100.99  100.40  100.89   3113532.0   -0.041  -0.05%   \n",
       "3 2013-05-13   26.60  27.325  26.531   26.82  29009648.0    0.140   0.52%   \n",
       "4 2013-07-10  291.41  293.34  289.40  292.33   1822877.0    0.800   0.27%   \n",
       "\n",
       "   adjclose      tradeval  tradevol symbol  \n",
       "0   25.7300  523595607.18   66068.0     FB  \n",
       "1   81.5900  555207178.14   32582.0    MCD  \n",
       "2   82.8798  313733616.64   16412.0    MCD  \n",
       "3   26.8200  782579320.46   90803.0     FB  \n",
       "4  292.3300  531832345.31   11812.0   AMZN  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf = spark.read.csv(DB_HOST+TABLE_STOCK_PRICES, header=True, inferSchema=True) \\\n",
    "    .dropDuplicates(['date', 'symbol']).toPandas()\n",
    "print(pdf.info())\n",
    "pdf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>changed</th>\n",
       "      <th>changep</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>tradeval</th>\n",
       "      <th>tradevol</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5275</th>\n",
       "      <td>2013-04-02</td>\n",
       "      <td>262.40</td>\n",
       "      <td>265.89</td>\n",
       "      <td>260.55</td>\n",
       "      <td>263.322</td>\n",
       "      <td>2631038.0</td>\n",
       "      <td>1.712</td>\n",
       "      <td>0.65%</td>\n",
       "      <td>263.3220</td>\n",
       "      <td>693325169.20</td>\n",
       "      <td>17760.0</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>2013-04-02</td>\n",
       "      <td>25.77</td>\n",
       "      <td>26.12</td>\n",
       "      <td>25.30</td>\n",
       "      <td>25.420</td>\n",
       "      <td>35124893.0</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>-0.43%</td>\n",
       "      <td>25.4200</td>\n",
       "      <td>904220577.12</td>\n",
       "      <td>107077.0</td>\n",
       "      <td>FB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>2013-04-02</td>\n",
       "      <td>99.40</td>\n",
       "      <td>100.42</td>\n",
       "      <td>99.025</td>\n",
       "      <td>100.260</td>\n",
       "      <td>5136501.0</td>\n",
       "      <td>0.994</td>\n",
       "      <td>1.22%</td>\n",
       "      <td>82.3622</td>\n",
       "      <td>513202156.02</td>\n",
       "      <td>24959.0</td>\n",
       "      <td>MCD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9859</th>\n",
       "      <td>2013-04-02</td>\n",
       "      <td>183.90</td>\n",
       "      <td>185.1799</td>\n",
       "      <td>176.10</td>\n",
       "      <td>176.690</td>\n",
       "      <td>4610979.0</td>\n",
       "      <td>-0.820</td>\n",
       "      <td>-3.15%</td>\n",
       "      <td>25.2414</td>\n",
       "      <td>828031668.71</td>\n",
       "      <td>27837.0</td>\n",
       "      <td>NFLX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5482</th>\n",
       "      <td>2013-04-02</td>\n",
       "      <td>43.60</td>\n",
       "      <td>45.50</td>\n",
       "      <td>43.5101</td>\n",
       "      <td>44.340</td>\n",
       "      <td>6621439.0</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.93%</td>\n",
       "      <td>44.3400</td>\n",
       "      <td>294906438.13</td>\n",
       "      <td>28077.0</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date    open      high      low    close      volume  changed  \\\n",
       "5275 2013-04-02  262.40    265.89   260.55  263.322   2631038.0    1.712   \n",
       "2003 2013-04-02   25.77     26.12    25.30   25.420  35124893.0   -0.110   \n",
       "2059 2013-04-02   99.40    100.42   99.025  100.260   5136501.0    0.994   \n",
       "9859 2013-04-02  183.90  185.1799   176.10  176.690   4610979.0   -0.820   \n",
       "5482 2013-04-02   43.60     45.50  43.5101   44.340   6621439.0    0.410   \n",
       "\n",
       "     changep  adjclose      tradeval  tradevol symbol  \n",
       "5275   0.65%  263.3220  693325169.20   17760.0   AMZN  \n",
       "2003  -0.43%   25.4200  904220577.12  107077.0     FB  \n",
       "2059   1.22%   82.3622  513202156.02   24959.0    MCD  \n",
       "9859  -3.15%   25.2414  828031668.71   27837.0   NFLX  \n",
       "5482   0.93%   44.3400  294906438.13   28077.0   TSLA  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.sort_values(by=['date', 'symbol'], ascending=True).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality-check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass into `args` argument\n",
    "\n",
    "STOCKS = ['FB', 'GOOG', 'AMZN', 'TRMT', 'TSLA', 'MCD', 'NFLX']\n",
    "DB_HOST = ''\n",
    "\n",
    "# Table names: update to add '/' in the final code.\n",
    "TABLE_STOCK_INFO_NASDAQ = 'test_data/raw/stock_info_nasdaq'\n",
    "TABLE_STOCK_INFO_NYSE = 'test_data/raw/stock_info_nyse'\n",
    "TABLE_STOCK_PRICES = 'test_data/raw/prices'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARN:root:(SUCCESS) Table test_data/raw/prices has 10654 rows.\n"
     ]
    }
   ],
   "source": [
    "if STOCKS is None or len(STOCKS) == 0:\n",
    "    check_basic_quality(logger, DB_HOST, TABLE_STOCK_INFO_NASDAQ)\n",
    "    check_basic_quality(logger, DB_HOST, TABLE_STOCK_INFO_NYSE)\n",
    "check_basic_quality(logger, DB_HOST, TABLE_STOCK_PRICES, table_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Combine Datasets\n",
    "\n",
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass into `args` argument\n",
    "\n",
    "YESTERDAY_DATE = '2019-12-12'\n",
    "AWS_ACCESS_KEY_ID = config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "AWS_SECRET_ACCESS_KEY = config['AWS']['AWS_SECRET_ACCESS_KEY']\n",
    "DB_HOST = ''\n",
    "\n",
    "# Table names: update to add '/' in the final code.\n",
    "TABLE_STOCK_PRICES = 'test_data/raw/prices'\n",
    "TABLE_SHORT_INTERESTS_NASDAQ = 'test_data/raw/short_interests_nasdaq' \n",
    "TABLE_SHORT_INTERESTS_NYSE = 'test_data/raw/short_interests_nyse'\n",
    "TABLE_SHORT_ANALYSIS = 'test_data/processed/short_analysis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARN:root:Creating table test_data/processed/short_analysis\n",
      "WARN:root:done!\n"
     ]
    }
   ],
   "source": [
    "create_table = not(spark_table_exists(DB_HOST, TABLE_SHORT_ANALYSIS))\n",
    "\n",
    "sdf_shorts = spark.read.csv([DB_HOST+TABLE_SHORT_INTERESTS_NASDAQ, DB_HOST+TABLE_SHORT_INTERESTS_NYSE], header=True, inferSchema=True)\n",
    "sdf_shorts = sdf_shorts.withColumn('Date', sdf_shorts['Date'].cast(T.DateType()))\n",
    "\n",
    "sdf_shorts = sdf_shorts.groupby(['Date', 'Symbol']) \\\n",
    "                 .agg(F.sum(sdf_shorts['ShortExemptVolume']).alias('short_exempt_volume'),\n",
    "                      F.sum(sdf_shorts['ShortVolume']).alias('short_volume'),\n",
    "                      F.sum(sdf_shorts['TotalVolume']).alias('total_volume')\n",
    "                     )\n",
    "sdf_prices = spark.read.csv(DB_HOST+TABLE_STOCK_PRICES, header=True, inferSchema=True) \\\n",
    "             .dropDuplicates(['date', 'symbol'])\n",
    "sdf_prices = sdf_prices.withColumn('date', sdf_prices['date'].cast(T.DateType()))\n",
    "\n",
    "if create_table == False:\n",
    "    sdf_shorts = sdf_shorts.filter(sdf_shorts['Date'] >= F.to_date(F.lit(YESTERDAY_DATE)))\n",
    "    sdf_prices = sdf_prices.filter(sdf_prices['date'] >= F.to_date(F.lit(YESTERDAY_DATE)))\n",
    "\n",
    "sdf_short_analysis = sdf_shorts.join(sdf_prices, (sdf_shorts['Date'] == sdf_prices['date']) & \\\n",
    "                                     (sdf_shorts['Symbol'] == sdf_prices['symbol']), how='inner') \\\n",
    "                               .drop(sdf_shorts['Date']).drop(sdf_shorts['Symbol'])\n",
    "\n",
    "mode = 'overwrite'\n",
    "if create_table == False:\n",
    "    logger.warn(\"Appending to table {}\".format(DB_HOST+TABLE_SHORT_ANALYSIS))\n",
    "    mode = 'append'\n",
    "else:\n",
    "    logger.warn(\"Creating table {}\".format(DB_HOST+TABLE_SHORT_ANALYSIS))\n",
    "\n",
    "# Coalesce is a must to avoid multiple headers.\n",
    "sdf_short_analysis.coalesce(1).write.mode(mode).csv(DB_HOST+TABLE_SHORT_ANALYSIS, header=True)\n",
    "\n",
    "delete_path(spark, DB_HOST, TABLE_SHORT_ANALYSIS+\".csv\")\n",
    "copyMerge(spark, DB_HOST, DB_HOST+TABLE_SHORT_ANALYSIS, DB_HOST+TABLE_SHORT_ANALYSIS+\".csv\")\n",
    "\n",
    "logger.warn(\"done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 940084 entries, 0 to 940083\n",
      "Data columns (total 5 columns):\n",
      "Date                   940084 non-null object\n",
      "Symbol                 940084 non-null object\n",
      "short_exempt_volume    940084 non-null float64\n",
      "short_volume           940084 non-null float64\n",
      "total_volume           940084 non-null float64\n",
      "dtypes: float64(3), object(2)\n",
      "memory usage: 35.9+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10549 entries, 0 to 10548\n",
      "Data columns (total 12 columns):\n",
      "date        10548 non-null object\n",
      "open        10548 non-null object\n",
      "high        10548 non-null object\n",
      "low         10548 non-null object\n",
      "close       10548 non-null float64\n",
      "volume      10548 non-null float64\n",
      "changed     10548 non-null float64\n",
      "changep     10548 non-null object\n",
      "adjclose    10548 non-null float64\n",
      "tradeval    10548 non-null object\n",
      "tradevol    10548 non-null float64\n",
      "symbol      10548 non-null object\n",
      "dtypes: float64(5), object(7)\n",
      "memory usage: 989.0+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3135 entries, 0 to 3134\n",
      "Data columns (total 15 columns):\n",
      "short_exempt_volume    3135 non-null float64\n",
      "short_volume           3135 non-null float64\n",
      "total_volume           3135 non-null float64\n",
      "date                   3135 non-null object\n",
      "open                   3135 non-null object\n",
      "high                   3135 non-null object\n",
      "low                    3135 non-null object\n",
      "close                  3135 non-null float64\n",
      "volume                 3135 non-null int32\n",
      "changed                3135 non-null float64\n",
      "changep                3135 non-null object\n",
      "adjclose               3135 non-null float64\n",
      "tradeval               3135 non-null object\n",
      "tradevol               3135 non-null int32\n",
      "symbol                 3135 non-null object\n",
      "dtypes: float64(6), int32(2), object(7)\n",
      "memory usage: 343.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df_short = sdf_shorts.toPandas()\n",
    "df_prices = sdf_prices.toPandas()\n",
    "df_short_analysis = sdf_short_analysis.toPandas()\n",
    "\n",
    "print(df_short.info())\n",
    "print(df_prices.info())\n",
    "print(df_short_analysis.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>short_exempt_volume</th>\n",
       "      <th>short_volume</th>\n",
       "      <th>total_volume</th>\n",
       "      <th>source_url</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>changed</th>\n",
       "      <th>changep</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>tradeval</th>\n",
       "      <th>tradevol</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>418961.0</td>\n",
       "      <td>753385.0</td>\n",
       "      <td>https://www.quandl.com/api/v3/datasets/FINRA/F...</td>\n",
       "      <td>2013-05-01</td>\n",
       "      <td>215.92</td>\n",
       "      <td>217.389</td>\n",
       "      <td>211.65</td>\n",
       "      <td>212.91</td>\n",
       "      <td>2622654</td>\n",
       "      <td>-0.451</td>\n",
       "      <td>-1.46%</td>\n",
       "      <td>30.4157</td>\n",
       "      <td>561027949.42</td>\n",
       "      <td>14673</td>\n",
       "      <td>NFLX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37360.0</td>\n",
       "      <td>6060485.0</td>\n",
       "      <td>20502608.0</td>\n",
       "      <td>https://www.quandl.com/api/v3/datasets/FINRA/F...</td>\n",
       "      <td>2013-05-06</td>\n",
       "      <td>28.33</td>\n",
       "      <td>28.46</td>\n",
       "      <td>27.48</td>\n",
       "      <td>27.57</td>\n",
       "      <td>43862625</td>\n",
       "      <td>-0.741</td>\n",
       "      <td>-2.62%</td>\n",
       "      <td>27.5700</td>\n",
       "      <td>1219158766.94</td>\n",
       "      <td>120016</td>\n",
       "      <td>FB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>635427.0</td>\n",
       "      <td>1388246.0</td>\n",
       "      <td>https://www.quandl.com/api/v3/datasets/FINRA/F...</td>\n",
       "      <td>2013-05-06</td>\n",
       "      <td>209.63</td>\n",
       "      <td>212.45</td>\n",
       "      <td>204.02</td>\n",
       "      <td>210.69</td>\n",
       "      <td>4532918</td>\n",
       "      <td>-0.394</td>\n",
       "      <td>-1.29%</td>\n",
       "      <td>30.0985</td>\n",
       "      <td>949314738.05</td>\n",
       "      <td>26760</td>\n",
       "      <td>NFLX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300.0</td>\n",
       "      <td>451077.0</td>\n",
       "      <td>952404.0</td>\n",
       "      <td>https://www.quandl.com/api/v3/datasets/FINRA/F...</td>\n",
       "      <td>2013-05-09</td>\n",
       "      <td>258.73</td>\n",
       "      <td>263.55</td>\n",
       "      <td>256.88</td>\n",
       "      <td>260.16</td>\n",
       "      <td>2769255</td>\n",
       "      <td>1.480</td>\n",
       "      <td>0.57%</td>\n",
       "      <td>260.1600</td>\n",
       "      <td>723085024.78</td>\n",
       "      <td>17822</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>342728.0</td>\n",
       "      <td>1335921.0</td>\n",
       "      <td>https://www.quandl.com/api/v3/datasets/FINRA/F...</td>\n",
       "      <td>2013-06-28</td>\n",
       "      <td>276.19</td>\n",
       "      <td>279.83</td>\n",
       "      <td>276.19</td>\n",
       "      <td>277.69</td>\n",
       "      <td>3193262</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.05%</td>\n",
       "      <td>277.6900</td>\n",
       "      <td>889020787.27</td>\n",
       "      <td>14332</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   short_exempt_volume  short_volume  total_volume  \\\n",
       "0                  0.0      418961.0      753385.0   \n",
       "1              37360.0     6060485.0    20502608.0   \n",
       "2                  0.0      635427.0     1388246.0   \n",
       "3                300.0      451077.0      952404.0   \n",
       "4                  0.0      342728.0     1335921.0   \n",
       "\n",
       "                                          source_url        date    open  \\\n",
       "0  https://www.quandl.com/api/v3/datasets/FINRA/F...  2013-05-01  215.92   \n",
       "1  https://www.quandl.com/api/v3/datasets/FINRA/F...  2013-05-06   28.33   \n",
       "2  https://www.quandl.com/api/v3/datasets/FINRA/F...  2013-05-06  209.63   \n",
       "3  https://www.quandl.com/api/v3/datasets/FINRA/F...  2013-05-09  258.73   \n",
       "4  https://www.quandl.com/api/v3/datasets/FINRA/F...  2013-06-28  276.19   \n",
       "\n",
       "      high     low   close    volume  changed changep  adjclose  \\\n",
       "0  217.389  211.65  212.91   2622654   -0.451  -1.46%   30.4157   \n",
       "1    28.46   27.48   27.57  43862625   -0.741  -2.62%   27.5700   \n",
       "2   212.45  204.02  210.69   4532918   -0.394  -1.29%   30.0985   \n",
       "3   263.55  256.88  260.16   2769255    1.480   0.57%  260.1600   \n",
       "4   279.83  276.19  277.69   3193262    0.140   0.05%  277.6900   \n",
       "\n",
       "        tradeval  tradevol symbol  \n",
       "0   561027949.42     14673   NFLX  \n",
       "1  1219158766.94    120016     FB  \n",
       "2   949314738.05     26760   NFLX  \n",
       "3   723085024.78     17822   AMZN  \n",
       "4   889020787.27     14332   AMZN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.parquet(DB_HOST+TABLE_SHORT_ANALYSIS).toPandas().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.parquet(DB_HOST+TABLE_SHORT_ANALYSIS).repartition(1).write.mode('overwrite').format('csv').save(DB_HOST+TABLE_SHORT_ANALYSIS+\".csv\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality-check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass into `args` argument\n",
    "\n",
    "DB_HOST = ''\n",
    "\n",
    "# Table names: update to add '/' in the final code.\n",
    "TABLE_SHORT_ANALYSIS = 'test_data/processed/short_analysis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARN:root:(SUCCESS) Table test_data/processed/short_analysis has 19087 rows.\n"
     ]
    }
   ],
   "source": [
    "check_basic_quality(logger, DB_HOST, TABLE_SHORT_ANALYSIS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sdf.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>short_exempt_volume</th>\n",
       "      <th>short_volume</th>\n",
       "      <th>total_volume</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>changed</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>tradevol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.054800e+04</td>\n",
       "      <td>1.054800e+04</td>\n",
       "      <td>1.054800e+04</td>\n",
       "      <td>10548.000000</td>\n",
       "      <td>1.054800e+04</td>\n",
       "      <td>10548.000000</td>\n",
       "      <td>10548.000000</td>\n",
       "      <td>1.054800e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.186437e+04</td>\n",
       "      <td>1.403028e+06</td>\n",
       "      <td>3.208060e+06</td>\n",
       "      <td>394.143509</td>\n",
       "      <td>9.086290e+06</td>\n",
       "      <td>0.389712</td>\n",
       "      <td>374.410873</td>\n",
       "      <td>6.666282e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.619000e+04</td>\n",
       "      <td>2.289725e+06</td>\n",
       "      <td>5.337051e+06</td>\n",
       "      <td>422.500286</td>\n",
       "      <td>1.448612e+07</td>\n",
       "      <td>11.274337</td>\n",
       "      <td>429.671097</td>\n",
       "      <td>6.752694e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.940000</td>\n",
       "      <td>5.300000e+01</td>\n",
       "      <td>-139.360000</td>\n",
       "      <td>3.612400</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>2.772368e+05</td>\n",
       "      <td>6.956500e+05</td>\n",
       "      <td>120.627500</td>\n",
       "      <td>2.423723e+06</td>\n",
       "      <td>-1.401000</td>\n",
       "      <td>99.175000</td>\n",
       "      <td>2.628525e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.183000e+03</td>\n",
       "      <td>6.329955e+05</td>\n",
       "      <td>1.455506e+06</td>\n",
       "      <td>221.885000</td>\n",
       "      <td>4.423890e+06</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>196.520200</td>\n",
       "      <td>4.293400e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.187750e+03</td>\n",
       "      <td>1.543929e+06</td>\n",
       "      <td>3.499728e+06</td>\n",
       "      <td>496.172500</td>\n",
       "      <td>9.444361e+06</td>\n",
       "      <td>2.089250</td>\n",
       "      <td>428.165000</td>\n",
       "      <td>8.723925e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.653923e+06</td>\n",
       "      <td>4.887740e+07</td>\n",
       "      <td>1.201625e+08</td>\n",
       "      <td>2039.510000</td>\n",
       "      <td>3.653806e+08</td>\n",
       "      <td>558.460000</td>\n",
       "      <td>2039.510000</td>\n",
       "      <td>1.312878e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       short_exempt_volume  short_volume  total_volume         close  \\\n",
       "count         1.054800e+04  1.054800e+04  1.054800e+04  10548.000000   \n",
       "mean          1.186437e+04  1.403028e+06  3.208060e+06    394.143509   \n",
       "std           4.619000e+04  2.289725e+06  5.337051e+06    422.500286   \n",
       "min           0.000000e+00  1.000000e+00  1.000000e+00      3.940000   \n",
       "25%           5.000000e+02  2.772368e+05  6.956500e+05    120.627500   \n",
       "50%           2.183000e+03  6.329955e+05  1.455506e+06    221.885000   \n",
       "75%           8.187750e+03  1.543929e+06  3.499728e+06    496.172500   \n",
       "max           1.653923e+06  4.887740e+07  1.201625e+08   2039.510000   \n",
       "\n",
       "             volume       changed      adjclose      tradevol  \n",
       "count  1.054800e+04  10548.000000  10548.000000  1.054800e+04  \n",
       "mean   9.086290e+06      0.389712    374.410873  6.666282e+04  \n",
       "std    1.448612e+07     11.274337    429.671097  6.752694e+04  \n",
       "min    5.300000e+01   -139.360000      3.612400  0.000000e+00  \n",
       "25%    2.423723e+06     -1.401000     99.175000  2.628525e+04  \n",
       "50%    4.423890e+06      0.080000    196.520200  4.293400e+04  \n",
       "75%    9.444361e+06      2.089250    428.165000  8.723925e+04  \n",
       "max    3.653806e+08    558.460000   2039.510000  1.312878e+06  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10548 entries, 0 to 10547\n",
      "Data columns (total 14 columns):\n",
      "short_exempt_volume    10548 non-null float64\n",
      "short_volume           10548 non-null float64\n",
      "total_volume           10548 non-null float64\n",
      "source_url             10548 non-null object\n",
      "open                   10548 non-null object\n",
      "high                   10548 non-null object\n",
      "low                    10548 non-null object\n",
      "close                  10548 non-null float64\n",
      "volume                 10548 non-null int32\n",
      "changed                10548 non-null float64\n",
      "changep                10548 non-null object\n",
      "adjclose               10548 non-null float64\n",
      "tradeval               10548 non-null object\n",
      "tradevol               10548 non-null int32\n",
      "dtypes: float64(6), int32(2), object(6)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- Best practices: https://towardsdatascience.com/apache-airflow-tips-and-best-practices-ff64ce92ef8\n",
    "- Write/store dataframe as textfile: https://stackoverflow.com/questions/44537889/write-store-dataframe-in-text-file\n",
    "- Delete hdfs path: https://stackoverflow.com/a/55952480/278191\n",
    "- Delete hdfs path in S3: http://bigdatatech.taleia.software/2015/12/28/deleting-a-amazon-s3-path-from-apache-spark/\n",
    "- Import java class in python: https://stackoverflow.com/questions/33544105/running-custom-java-class-in-pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
