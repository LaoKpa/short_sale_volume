{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Pipeline on Local Spark\n",
    "\n",
    "1. Setting up\n",
    "2. Helpers\n",
    "3. Pull stock info\n",
    "4. Pull short interests\n",
    "5. Pull stock prices\n",
    "6. Combine datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting Up\n",
    "\n",
    "We want to have a logging feature that works for both Jupyter notebook and Spark environments.\n",
    "\n",
    "1. As it turned out, Spark has \"WARN\" but does not have \"WARNING\" level, while in current Python (3.6.x), \"WARN\" is deprecated, \"WARNING\" should be used instead.\n",
    "2. Therefore, we create a custom \"WARN\" level as well as function `logger.warn` for Jupyter notebook.\n",
    "3. As shown in [this StackOverflow post](https://stackoverflow.com/questions/35326814/change-level-logged-to-ipython-jupyter-notebook), this is not straightforward due to a Jupyter notebook bug. We need to workaround this by specifying an invalid value first, which we do in the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:The 'log_level' trait of an IPKernelApp instance must be any of (0, 10, 20, 30, 40, 50, 'DEBUG', 'INFO', 'WARN', 'ERROR', 'CRITICAL'), but a value of 'WORKAROUND' <class 'str'> was specified.\n",
      "WARN:root:hello\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['airflow/config.cfg']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Run this, but don't copy into etl scripts\n",
    "# workaround via specifying an invalid value first\n",
    "%config Application.log_level='WORKAROUND'\n",
    "import logging\n",
    "logging.WARN = 21\n",
    "logging.addLevelName(logging.WARN, 'WARN')\n",
    "\n",
    "def warn(self, message, *args, **kws):\n",
    "    if self.isEnabledFor(logging.WARN):\n",
    "        # Yes, logger takes its '*args' as 'args'.\n",
    "        self._log(logging.WARN, message, args, **kws) \n",
    "logging.Logger.warn = warn\n",
    "\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.WARN)\n",
    "logger.warn('hello')\n",
    "\n",
    "# ------------------\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "import pandas as pd\n",
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read('airflow/config.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell, and also copy to all etl scripts, or simply include in common.py\n",
    "\n",
    "import requests\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.sql import Row\n",
    "\n",
    "from py4j.java_gateway import java_import\n",
    "\n",
    "def delete_path(spark, host, path):\n",
    "    sc = spark.sparkContext\n",
    "    java_import(sc._gateway.jvm, \"java.net.URI\")\n",
    "    uri = sc._gateway.jvm.java.net.URI\n",
    "    fs = (sc._jvm.org\n",
    "          .apache.hadoop\n",
    "          .fs.FileSystem\n",
    "          .get(uri(host), sc._jsc.hadoopConfiguration())\n",
    "          )\n",
    "    fs.delete(sc._jvm.org.apache.hadoop.fs.Path(host+path), True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Copy this cell content to all etl scripts, but don't run here.\n",
    "\n",
    "Logger = spark._jvm.org.apache.log4j.Logger\n",
    "logger = Logger.getLogger(\"DAG\")\n",
    "spark.sparkContext.setLogLevel('WARN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_path(spark, 's3a://short-interest-effect', '/data/raw/stock_info_nasdaq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Helpers\n",
    "\n",
    "Include this code as helpers in all next etl scripts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS_ACCESS_KEY_ID = config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "AWS_SECRET_ACCESS_KEY = config['AWS']['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py4j.protocol import Py4JJavaError\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", AWS_ACCESS_KEY_ID)\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", AWS_SECRET_ACCESS_KEY)\n",
    "\n",
    "def spark_table_exists(host, table_path):\n",
    "    URI           = sc._gateway.jvm.java.net.URI\n",
    "    Path          = sc._gateway.jvm.org.apache.hadoop.fs.Path\n",
    "    FileSystem    = sc._gateway.jvm.org.apache.hadoop.fs.FileSystem\n",
    "    # Configuration = sc._gateway.jvm.org.apache.hadoop.conf.Configuration\n",
    "    Configuration = sc._jsc.hadoopConfiguration\n",
    "\n",
    "\n",
    "    fs = FileSystem.get(URI(host), Configuration())\n",
    "\n",
    "    try:\n",
    "        status = fs.listStatus(Path(table_path))\n",
    "\n",
    "        return True\n",
    "    except Py4JJavaError as e:\n",
    "        if 'FileNotFoundException' in str(e):\n",
    "            return False\n",
    "        else:\n",
    "            print(e)\n",
    "    \n",
    "    \n",
    "def check_basic_quality(logger, host, table_path, table_type='parquet'):\n",
    "    \"\"\" Checks quality of DAG.\n",
    "    \n",
    "    We do this by checking if the table exists and is not empty.\n",
    "    \n",
    "    Args:\n",
    "        - table_type(str): 'parquet' or 'csv'\n",
    "    \"\"\"\n",
    "    if not spark_table_exists(host, table_path):\n",
    "        logger.warn(\"(FAIL) Table {} does not exist\".format(host+table_path))\n",
    "    else:\n",
    "        if table_type == 'parquet':\n",
    "            count = spark.read.parquet(host+table_path).count()\n",
    "        elif table_type == 'csv':\n",
    "            count = spark.read.csv(host+table_path, header=True).count()\n",
    "            \n",
    "        if count == 0:\n",
    "            logger.warn(\"(FAIL) Table {} is empty.\".format(host+table_path))\n",
    "        else:\n",
    "            logger.warn(\"(SUCCESS) Table {} has {} rows.\".format(host+table_path, count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARN:root:(SUCCESS) Table s3a://short-interest-effect/data/test_table has 1706 rows.\n"
     ]
    }
   ],
   "source": [
    "print(spark_table_exists('s3a://short-interest-effect', 'data/test_table')) # Fails due to lack of '/' before the table path\n",
    "print(spark_table_exists('s3a://short-interest-effect', '/data/test_table'))\n",
    "print(spark_table_exists('', 'test_data/test_table'))\n",
    "\n",
    "check_basic_quality(logger, 's3a://short-interest-effect', '/data/test_table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pull Stock Info\n",
    "\n",
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass into `args` argument\n",
    "\n",
    "URL_NASDAQ = 'https://old.nasdaq.com/screening/companies-by-name.aspx?letter=0&exchange=nasdaq&render=download'\n",
    "URL_NYSE = 'https://old.nasdaq.com/screening/companies-by-name.aspx?letter=0&exchange=nyse&render=download'\n",
    "\n",
    "DB_HOST = ''\n",
    "# Table names: update to add '/' in the final code.\n",
    "TABLE_STOCK_INFO_NASDAQ = 'test_data/raw/stock_info_nasdaq'\n",
    "TABLE_STOCK_INFO_NYSE = 'test_data/raw/stock_info_nyse'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# The EMR cluster does not have pandas so we cannot use this.\n",
    "import pandas as pd\n",
    "\n",
    "def pull_stock_info(url, table_path):\n",
    "    try:\n",
    "        df = pd.read_csv(url)\n",
    "        df['MarketCap'] = df['MarketCap'].astype(str)\n",
    "        df['Sector'] = df['Sector'].astype(str)\n",
    "        df['industry'] = df['industry'].astype(str)\n",
    "        spark.createDataFrame(df) \\\n",
    "            .withColumnRenamed('Summary Quote', 'SummaryQuote') \\\n",
    "            .withColumnRenamed('Unnamed: 8', '_c8') \\\n",
    "            .drop('_c8') \\\n",
    "            .write.mode('overwrite').parquet(table_path)\n",
    "        logger.warn(\"Stored data from {} to {}\".format(url, table_path))\n",
    "    except IOError as e:\n",
    "        logger.warn(\"Failed to connect to {}. We will use existing stock info data if they have been created.\".format(url))\n",
    "        \n",
    "    \n",
    "pull_stock_info(URL_NASDAQ, DB_HOST+TABLE_STOCK_INFO_NASDAQ)\n",
    "pull_stock_info(URL_NYSE, DB_HOST+TABLE_STOCK_INFO_NYSE)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# On the EMR cluster, this code returns an error:\n",
    "# \"AttributeError: 'RDD' object has no attribute '_get_object_id'\\n\"\n",
    "# quite likely due to loading CSV from string: spark.read.csv(data, header=True)\n",
    "\n",
    "def pull_stock_info(url, table_path):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200 or response.status_code == 201:\n",
    "        content = response.content.decode('utf-8')\n",
    "        data = spark.sparkContext.parallelize(content.splitlines())\n",
    "        logger.warn(\"data is {}\".format(data))\n",
    "        df = spark.read.csv(data, header=True) \\\n",
    "            .withColumnRenamed('Summary Quote', 'SummaryQuote') \\\n",
    "            .drop('_c8') \\\n",
    "            .write.mode('overwrite').parquet(table_path)\n",
    "        logger.warn(\"Stored data from {} to {}\".format(url, table_path))\n",
    "    else:\n",
    "        logger.warn(\"Failed to connect to {}. We will use existing stock info data if they have been created.\".format(url))\n",
    "        \n",
    "    \n",
    "pull_stock_info(URL_NASDAQ, DB_HOST+TABLE_STOCK_INFO_NASDAQ)\n",
    "pull_stock_info(URL_NYSE, DB_HOST+TABLE_STOCK_INFO_NYSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARN:root:Stored data from https://old.nasdaq.com/screening/companies-by-name.aspx?letter=0&exchange=nasdaq&render=download to test_data/raw/stock_info_nasdaq\n",
      "WARN:root:Stored data from https://old.nasdaq.com/screening/companies-by-name.aspx?letter=0&exchange=nyse&render=download to test_data/raw/stock_info_nyse\n"
     ]
    }
   ],
   "source": [
    "def pull_stock_info(url, db_host, table_path):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200 or response.status_code == 201:\n",
    "        content = response.content.decode('utf-8')\n",
    "        content = content.replace('Summary Quote', 'SummaryQuote')\n",
    "        delete_path(spark, db_host, table_path)\n",
    "        df = spark.createDataFrame([[content]], ['info_csv'])\n",
    "        df.rdd.map(lambda x: x['info_csv'].replace(\"[\",\"\").replace(\"]\", \"\")).saveAsTextFile(db_host+table_path)\n",
    "        logger.warn(\"Stored data from {} to {}\".format(url, db_host+table_path))\n",
    "    else:\n",
    "        logger.warn(\"Failed to connect to {}. We will use existing stock info data if they have been created.\".format(url))\n",
    "        \n",
    "    \n",
    "pull_stock_info(URL_NASDAQ, DB_HOST, TABLE_STOCK_INFO_NASDAQ)\n",
    "pull_stock_info(URL_NYSE, DB_HOST, TABLE_STOCK_INFO_NYSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Name</th>\n",
       "      <th>LastSale</th>\n",
       "      <th>MarketCap</th>\n",
       "      <th>IPOyear</th>\n",
       "      <th>Sector</th>\n",
       "      <th>industry</th>\n",
       "      <th>SummaryQuote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3582</td>\n",
       "      <td>3582</td>\n",
       "      <td>3582</td>\n",
       "      <td>3582</td>\n",
       "      <td>3582</td>\n",
       "      <td>3582</td>\n",
       "      <td>3582</td>\n",
       "      <td>3582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3582</td>\n",
       "      <td>3151</td>\n",
       "      <td>2845</td>\n",
       "      <td>2839</td>\n",
       "      <td>44</td>\n",
       "      <td>13</td>\n",
       "      <td>128</td>\n",
       "      <td>3582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>FPXI</td>\n",
       "      <td>Barclays PLC</td>\n",
       "      <td>1.6</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>n/a</td>\n",
       "      <td>https://old.nasdaq.com/symbol/siga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>307</td>\n",
       "      <td>1889</td>\n",
       "      <td>785</td>\n",
       "      <td>522</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Symbol          Name LastSale MarketCap IPOyear       Sector industry  \\\n",
       "count    3582          3582     3582      3582    3582         3582     3582   \n",
       "unique   3582          3151     2845      2839      44           13      128   \n",
       "top      FPXI  Barclays PLC      1.6       n/a     n/a  Health Care      n/a   \n",
       "freq        1            10        9       307    1889          785      522   \n",
       "\n",
       "                              SummaryQuote  \n",
       "count                                 3582  \n",
       "unique                                3582  \n",
       "top     https://old.nasdaq.com/symbol/siga  \n",
       "freq                                     1  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.csv(DB_HOST+TABLE_STOCK_INFO_NASDAQ, header=True, inferSchema=True) \\\n",
    "               .drop('_c8').toPandas()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Name</th>\n",
       "      <th>LastSale</th>\n",
       "      <th>MarketCap</th>\n",
       "      <th>IPOyear</th>\n",
       "      <th>Sector</th>\n",
       "      <th>industry</th>\n",
       "      <th>SummaryQuote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3092</td>\n",
       "      <td>3092</td>\n",
       "      <td>3092</td>\n",
       "      <td>3092</td>\n",
       "      <td>3092</td>\n",
       "      <td>3092</td>\n",
       "      <td>3092</td>\n",
       "      <td>3092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3092</td>\n",
       "      <td>2438</td>\n",
       "      <td>2385</td>\n",
       "      <td>1924</td>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>133</td>\n",
       "      <td>3092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>CS</td>\n",
       "      <td>Bank of America Corporation</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>https://old.nasdaq.com/symbol/hpf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>106</td>\n",
       "      <td>700</td>\n",
       "      <td>1658</td>\n",
       "      <td>1010</td>\n",
       "      <td>1010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Symbol                         Name LastSale MarketCap IPOyear Sector  \\\n",
       "count    3092                         3092     3092      3092    3092   3092   \n",
       "unique   3092                         2438     2385      1924      36     13   \n",
       "top        CS  Bank of America Corporation      n/a       n/a     n/a    n/a   \n",
       "freq        1                           14      106       700    1658   1010   \n",
       "\n",
       "       industry                       SummaryQuote  \n",
       "count      3092                               3092  \n",
       "unique      133                               3092  \n",
       "top         n/a  https://old.nasdaq.com/symbol/hpf  \n",
       "freq       1010                                  1  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.csv(DB_HOST+TABLE_STOCK_INFO_NYSE,\n",
    "                    header=True, ignoreLeadingWhiteSpace=True, inferSchema=True) \\\n",
    "               .drop('_c8').toPandas()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Name</th>\n",
       "      <th>LastSale</th>\n",
       "      <th>MarketCap</th>\n",
       "      <th>IPOyear</th>\n",
       "      <th>Sector</th>\n",
       "      <th>industry</th>\n",
       "      <th>SummaryQuote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DDD</td>\n",
       "      <td>3D Systems Corporation</td>\n",
       "      <td>11.9</td>\n",
       "      <td>$1.41B</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Computer Software: Prepackaged Software</td>\n",
       "      <td>https://old.nasdaq.com/symbol/ddd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MMM</td>\n",
       "      <td>3M Company</td>\n",
       "      <td>179.78</td>\n",
       "      <td>$103.38B</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Medical/Dental Instruments</td>\n",
       "      <td>https://old.nasdaq.com/symbol/mmm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WBAI</td>\n",
       "      <td>500.com Limited</td>\n",
       "      <td>8</td>\n",
       "      <td>$343.99M</td>\n",
       "      <td>2013</td>\n",
       "      <td>Consumer Services</td>\n",
       "      <td>Services-Misc. Amusement &amp; Recreation</td>\n",
       "      <td>https://old.nasdaq.com/symbol/wbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WUBA</td>\n",
       "      <td>58.com Inc.</td>\n",
       "      <td>69.18</td>\n",
       "      <td>$10.34B</td>\n",
       "      <td>2013</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Computer Software: Programming, Data Processing</td>\n",
       "      <td>https://old.nasdaq.com/symbol/wuba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EGHT</td>\n",
       "      <td>8x8 Inc</td>\n",
       "      <td>20.1</td>\n",
       "      <td>$2.01B</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Technology</td>\n",
       "      <td>EDP Services</td>\n",
       "      <td>https://old.nasdaq.com/symbol/eght</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol                    Name LastSale MarketCap IPOyear  \\\n",
       "0    DDD  3D Systems Corporation     11.9    $1.41B     n/a   \n",
       "1    MMM              3M Company   179.78  $103.38B     n/a   \n",
       "2   WBAI         500.com Limited        8  $343.99M    2013   \n",
       "3   WUBA             58.com Inc.    69.18   $10.34B    2013   \n",
       "4   EGHT                 8x8 Inc     20.1    $2.01B     n/a   \n",
       "\n",
       "              Sector                                         industry  \\\n",
       "0         Technology          Computer Software: Prepackaged Software   \n",
       "1        Health Care                       Medical/Dental Instruments   \n",
       "2  Consumer Services            Services-Misc. Amusement & Recreation   \n",
       "3         Technology  Computer Software: Programming, Data Processing   \n",
       "4         Technology                                     EDP Services   \n",
       "\n",
       "                         SummaryQuote  \n",
       "0   https://old.nasdaq.com/symbol/ddd  \n",
       "1   https://old.nasdaq.com/symbol/mmm  \n",
       "2  https://old.nasdaq.com/symbol/wbai  \n",
       "3  https://old.nasdaq.com/symbol/wuba  \n",
       "4  https://old.nasdaq.com/symbol/eght  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality-check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_basic_quality(logger, DB_HOST, TABLE_STOCK_INFO_NASDAQ, table_type='csv')\n",
    "check_basic_quality(logger, DB_HOST, TABLE_STOCK_INFO_NYSE, table_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pull Short Interest\n",
    "\n",
    "#### Parallelize based on stocks or parallelize based on returned data points?\n",
    "\n",
    "At the time of writing (2020-01-15), we have 3582 stocks from NASDAQ and 3092 stocks from NYSE. The earliest date is 2013-04-01, which accounts for nearly 1700 data points (261 working days each year).\n",
    "\n",
    "For each stock, we will need to connect to an external API (Quandl or QuoteMedia). This will take more of the processing time rather than data processing. Therefore, we parallelize based on the stocks rather than returned data points. This way, multiple Spark nodes can connect to different URLs and pull the data. The downside is, obviously, for each node we will have to iteratively process the data, but this is still faster as there are fewer data points than the stocks, at least until several years in the future (There might be a solution that allows each spark node to parallelize...).\n",
    "\n",
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exchange_map = {\n",
    "#     'nasdaq': 'FNSQ',\n",
    "#     'nyse': 'FNYX'\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2020-01-15', 763014.0, 15.0, 1201785.0]\n",
      "['Date', 'ShortVolume', 'ShortExemptVolume', 'TotalVolume']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'Date': '2020-01-15',\n",
       "  'ShortVolume': 763014.0,\n",
       "  'ShortExemptVolume': 15.0,\n",
       "  'TotalVolume': 1201785.0},\n",
       " {'Date': '2020-01-14',\n",
       "  'ShortVolume': 918212.0,\n",
       "  'ShortExemptVolume': 1.0,\n",
       "  'TotalVolume': 1539251.0}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://www.quandl.com/api/v3/datasets/FINRA/FNYX_FB?api_key={}\".format(config['Quandl']['API_KEY'])\n",
    "result = requests.get(url).json()\n",
    "print(result['dataset']['data'][0])\n",
    "print(result['dataset']['column_names'])\n",
    "col_names = [result['dataset']['column_names']] * len(result['dataset']['data'])\n",
    "newdata = []\n",
    "for i, cols in enumerate(col_names):\n",
    "    newdata.append(dict(zip(cols, result['dataset']['data'][i])))\n",
    "newdata[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write to single tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass into `args` argument\n",
    "\n",
    "START_DATE = config['App']['START_DATE']\n",
    "QUANDL_API_KEY = config['Quandl']['API_KEY']\n",
    "YESTERDAY_DATE = '2019-12-12'\n",
    "LIMIT = 1\n",
    "STOCKS = ['FB', 'GOOG', 'AMZN', 'TRMT', 'TSLA', 'MCD', 'NFLX']\n",
    "AWS_ACCESS_KEY_ID = config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "AWS_SECRET_ACCESS_KEY = config['AWS']['AWS_SECRET_ACCESS_KEY']\n",
    "DB_HOST = ''\n",
    "\n",
    "# Table names: update to add '/' in the final code.\n",
    "TABLE_STOCK_INFO_NASDAQ = 'test_data/raw/stock_info_nasdaq'\n",
    "TABLE_STOCK_INFO_NYSE = 'test_data/raw/stock_info_nyse'\n",
    "TABLE_SHORT_INTERESTS_NASDAQ = 'test_data/raw/short_interests_nasdaq' \n",
    "TABLE_SHORT_INTERESTS_NYSE = 'test_data/raw/short_interests_nyse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARN:root:Appending to table test_data/raw/short_interests_nasdaq\n",
      "WARN:root:done!\n",
      "WARN:root:Appending to table test_data/raw/short_interests_nyse\n",
      "WARN:root:done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.34 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "\n",
    "def convert_data(olddata, symbol, url):\n",
    "    col_names = olddata['dataset']['column_names']\n",
    "    col_names.append('Symbol')\n",
    "    col_names.append('SourceURL')\n",
    "    col_names_multiplied = [col_names] * len(olddata['dataset']['data'])\n",
    "    newdata = []\n",
    "    for i, cols in enumerate(col_names_multiplied):\n",
    "        datum = olddata['dataset']['data'][i]\n",
    "        datum.append(symbol)\n",
    "        datum.append(url)\n",
    "        newdata.append(dict(zip(cols, datum)))\n",
    "    return newdata\n",
    "\n",
    "\n",
    "def pull_short_interests(exchange, host, info_table_path, short_interests_table_path):\n",
    "\n",
    "    create_table = not(spark_table_exists(host, short_interests_table_path))\n",
    "        \n",
    "    def pull_exchange_short_interests_by_symbol(symbol):\n",
    "        \"\"\"\n",
    "        Return:\n",
    "            list of dicts [{'colname': value, ...}, ...]\n",
    "        \"\"\"\n",
    "        if create_table == True:\n",
    "            # If table does not exist, pull all data.\n",
    "            url = 'https://www.quandl.com/api/v3/datasets/FINRA/'+exchange+'_{}?start_date='+START_DATE+'&end_date='+YESTERDAY_DATE+'&api_key='+QUANDL_API_KEY\n",
    "        else:\n",
    "            # If table had existed, pull yesterday's data.\n",
    "            url = 'https://www.quandl.com/api/v3/datasets/FINRA/'+exchange+'_{}?start_date='+YESTERDAY_DATE+'&end_date='+YESTERDAY_DATE+'&api_key='+QUANDL_API_KEY\n",
    "\n",
    "        url = url.format(symbol)\n",
    "        response = requests.get(url)\n",
    "        newdata = []\n",
    "        if response.status_code in [200, 201]:\n",
    "            newdata = convert_data(response.json(), symbol, url)\n",
    "        return newdata\n",
    "\n",
    "    \n",
    "    # [{'colname': value, ...}, ...]\n",
    "    schema = T.ArrayType(\n",
    "                T.MapType(\n",
    "                    T.StringType(), T.StringType()\n",
    "                )\n",
    "             )\n",
    "    udf_pull_exchange_short_interests = F.udf(pull_exchange_short_interests_by_symbol, schema)\n",
    "\n",
    "    # Prepare list of stocks\n",
    "    if STOCKS is not None and len(STOCKS) > 0:\n",
    "        rdd1 = spark.sparkContext.parallelize(STOCKS)\n",
    "        row_rdd = rdd1.map(lambda x: Row(x))\n",
    "        df = spark.createDataFrame(row_rdd,['Symbol'])\n",
    "    else:\n",
    "        df = spark.read.parquet(host+info_table_path)\n",
    "        if LIMIT is not None:\n",
    "            df = df.limit(LIMIT)\n",
    "\n",
    "    df = df.withColumn('short_interests', udf_pull_exchange_short_interests('Symbol'))\n",
    "\n",
    "    # Convert [short_interests: [{col: val, ...}, ...]] to\n",
    "    # [{col: val, ...}, ...]\n",
    "    df = df.select(F.explode(df['short_interests']).alias('col')) \\\n",
    "         .rdd.map(lambda x: x['col'])\n",
    "\n",
    "    df_schema = T.StructType([T.StructField('Date', T.StringType(), False),\n",
    "                              T.StructField('ShortExemptVolume', T.StringType(), True),\n",
    "                              T.StructField('ShortVolume', T.StringType(), True),\n",
    "                              T.StructField('Symbol', T.StringType(), False),\n",
    "                              T.StructField('TotalVolume', T.StringType(), True),\n",
    "                              T.StructField('SourceURL', T.StringType(), True),\n",
    "                             ])\n",
    "    df = spark.createDataFrame(df, df_schema)\n",
    "    df = df.withColumn('Date', df['Date'].cast(T.DateType())) \\\n",
    "         .withColumn('ShortExemptVolume', df['ShortExemptVolume'].cast(T.DoubleType())) \\\n",
    "         .withColumn('ShortVolume', df['ShortVolume'].cast(T.DoubleType())) \\\n",
    "         .withColumn('TotalVolume', df['TotalVolume'].cast(T.DoubleType()))\n",
    "\n",
    "    if create_table:\n",
    "        logger.warn(\"Creating table {}\".format(host+short_interests_table_path))\n",
    "        df.write.mode('overwrite').parquet(host+short_interests_table_path)\n",
    "    else:\n",
    "        logger.warn(\"Appending to table {}\".format(host+short_interests_table_path))\n",
    "        df.write.mode('append').parquet(host+short_interests_table_path)\n",
    "        \n",
    "        # Drop duplicates later when we combine the datasets:\n",
    "        # 1. We do not want to waste S3 bandwidth.\n",
    "        # 2. Raw data are meant to be dirty. We are going to use only the final dataset for analysis.\n",
    "        # 3. If we really want to clean the datasets. Create another DAG for that.\n",
    "        # code:\n",
    "#         spark.read.parquet(host+short_interests_table_path).dropDuplicates(['Date']) \\\n",
    "#         .write.mode('append').parquet(host+short_interests_table_path)\n",
    "        \n",
    "    logger.warn(\"done!\")\n",
    "\n",
    "pull_short_interests('FNSQ', DB_HOST, TABLE_STOCK_INFO_NASDAQ, TABLE_SHORT_INTERESTS_NASDAQ)\n",
    "pull_short_interests('FNYX', DB_HOST, TABLE_STOCK_INFO_NYSE, TABLE_SHORT_INTERESTS_NYSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9080\n",
      "https://www.quandl.com/api/v3/datasets/FINRA/FNSQ_GOOG?start_date=2013-04-01&api_key=zhiR5Rz7eFUy_XNcZb2f\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ShortExemptVolume</th>\n",
       "      <th>ShortVolume</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>TotalVolume</th>\n",
       "      <th>SourceURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>119.0</td>\n",
       "      <td>135083.0</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>234811.0</td>\n",
       "      <td>https://www.quandl.com/api/v3/datasets/FINRA/F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>8177.0</td>\n",
       "      <td>1137057.0</td>\n",
       "      <td>FB</td>\n",
       "      <td>2244132.0</td>\n",
       "      <td>https://www.quandl.com/api/v3/datasets/FINRA/F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>7813.0</td>\n",
       "      <td>643374.0</td>\n",
       "      <td>NFLX</td>\n",
       "      <td>1124373.0</td>\n",
       "      <td>https://www.quandl.com/api/v3/datasets/FINRA/F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>2312.0</td>\n",
       "      <td>191325.0</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>609106.0</td>\n",
       "      <td>https://www.quandl.com/api/v3/datasets/FINRA/F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38432.0</td>\n",
       "      <td>TRMT</td>\n",
       "      <td>66421.0</td>\n",
       "      <td>https://www.quandl.com/api/v3/datasets/FINRA/F...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  ShortExemptVolume  ShortVolume Symbol  TotalVolume  \\\n",
       "0  2020-01-15              119.0     135083.0   GOOG     234811.0   \n",
       "1  2020-01-15             8177.0    1137057.0     FB    2244132.0   \n",
       "2  2020-01-15             7813.0     643374.0   NFLX    1124373.0   \n",
       "3  2020-01-15             2312.0     191325.0   AMZN     609106.0   \n",
       "4  2020-01-15                0.0      38432.0   TRMT      66421.0   \n",
       "\n",
       "                                           SourceURL  \n",
       "0  https://www.quandl.com/api/v3/datasets/FINRA/F...  \n",
       "1  https://www.quandl.com/api/v3/datasets/FINRA/F...  \n",
       "2  https://www.quandl.com/api/v3/datasets/FINRA/F...  \n",
       "3  https://www.quandl.com/api/v3/datasets/FINRA/F...  \n",
       "4  https://www.quandl.com/api/v3/datasets/FINRA/F...  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf = spark.read.parquet(DB_HOST+TABLE_SHORT_INTERESTS_NASDAQ).dropDuplicates(['Date', 'Symbol'])\n",
    "sdf = sdf.orderBy(sdf.Date.desc())\n",
    "print(sdf.count())\n",
    "df = sdf.toPandas()\n",
    "print(df['SourceURL'][0])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ShortExemptVolume</th>\n",
       "      <th>ShortVolume</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>TotalVolume</th>\n",
       "      <th>SourceURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9079</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>321547.0</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>627308.0</td>\n",
       "      <td>https://www.quandl.com/api/v3/datasets/FINRA/F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9076</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>3097667.0</td>\n",
       "      <td>FB</td>\n",
       "      <td>8349211.0</td>\n",
       "      <td>https://www.quandl.com/api/v3/datasets/FINRA/F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9077</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>246063.0</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>494596.0</td>\n",
       "      <td>https://www.quandl.com/api/v3/datasets/FINRA/F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9078</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>100.0</td>\n",
       "      <td>409150.0</td>\n",
       "      <td>NFLX</td>\n",
       "      <td>1078168.0</td>\n",
       "      <td>https://www.quandl.com/api/v3/datasets/FINRA/F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9075</th>\n",
       "      <td>2013-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1780043.0</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>5786214.0</td>\n",
       "      <td>https://www.quandl.com/api/v3/datasets/FINRA/F...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  ShortExemptVolume  ShortVolume Symbol  TotalVolume  \\\n",
       "9079  2013-04-01             1200.0     321547.0   AMZN     627308.0   \n",
       "9076  2013-04-01             5500.0    3097667.0     FB    8349211.0   \n",
       "9077  2013-04-01                0.0     246063.0   GOOG     494596.0   \n",
       "9078  2013-04-01              100.0     409150.0   NFLX    1078168.0   \n",
       "9075  2013-04-01                0.0    1780043.0   TSLA    5786214.0   \n",
       "\n",
       "                                              SourceURL  \n",
       "9079  https://www.quandl.com/api/v3/datasets/FINRA/F...  \n",
       "9076  https://www.quandl.com/api/v3/datasets/FINRA/F...  \n",
       "9077  https://www.quandl.com/api/v3/datasets/FINRA/F...  \n",
       "9078  https://www.quandl.com/api/v3/datasets/FINRA/F...  \n",
       "9075  https://www.quandl.com/api/v3/datasets/FINRA/F...  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['Date', 'Symbol'], ascending=True).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality-check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass into `args` argument\n",
    "\n",
    "STOCKS = ['FB', 'GOOG', 'AMZN', 'TRMT', 'TSLA', 'MCD', 'NFLX']\n",
    "DB_HOST = ''\n",
    "\n",
    "# Table names: update to add '/' in the final code.\n",
    "TABLE_STOCK_INFO_NASDAQ = 'test_data/raw/stock_info_nasdaq'\n",
    "TABLE_STOCK_INFO_NYSE = 'test_data/raw/stock_info_nyse'\n",
    "TABLE_SHORT_INTERESTS_NASDAQ = 'test_data/raw/short_interests_nasdaq' \n",
    "TABLE_SHORT_INTERESTS_NYSE = 'test_data/raw/short_interests_nyse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARN:root:(SUCCESS) Table test_data/raw/short_interests_nasdaq has 9085 rows.\n",
      "WARN:root:(SUCCESS) Table test_data/raw/short_interests_nyse has 10544 rows.\n"
     ]
    }
   ],
   "source": [
    "if STOCKS is None or len(STOCKS) == 0:\n",
    "    check_basic_quality(logger, DB_HOST, TABLE_STOCK_INFO_NASDAQ, table_type='csv')\n",
    "    check_basic_quality(logger, DB_HOST, TABLE_STOCK_INFO_NYSE, table_type='csv')\n",
    "check_basic_quality(logger, DB_HOST, TABLE_SHORT_INTERESTS_NASDAQ)\n",
    "check_basic_quality(logger, DB_HOST, TABLE_SHORT_INTERESTS_NYSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pull Stock Prices\n",
    "\n",
    "### Code (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass into `args` argument\n",
    "\n",
    "START_DATE = config['App']['START_DATE']\n",
    "QUANDL_API_KEY = config['Quandl']['API_KEY']\n",
    "YESTERDAY_DATE = '2019-12-12'\n",
    "LIMIT = 10\n",
    "STOCKS = ['FB', 'GOOG', 'AMZN', 'TRMT', 'TSLA', 'MCD', 'NFLX']\n",
    "AWS_ACCESS_KEY_ID = config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "AWS_SECRET_ACCESS_KEY = config['AWS']['AWS_SECRET_ACCESS_KEY']\n",
    "DB_HOST = ''\n",
    "\n",
    "# Table names: update to add '/' in the final code.\n",
    "TABLE_STOCK_INFO_NASDAQ = 'test_data/raw/stock_info_nasdaq'\n",
    "TABLE_STOCK_INFO_NYSE = 'test_data/raw/stock_info_nyse'\n",
    "TABLE_STOCK_PRICES = 'test_data/raw/prices'\n",
    "\n",
    "URL = \"\"\"http://app.quotemedia.com/quotetools/getHistoryDownload.csv?&webmasterId=501&startDay={sd}&startMonth={sm}&startYear={sy}&endDay={ed}&endMonth={em}&endYear={ey}&isRanged=true&symbol={sym}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include on top of the ETL script\n",
    "\n",
    "START_DAY = START_DATE.split('-')[2]\n",
    "# In QuoteMedia, months start from 0, so we adjust this variable.\n",
    "START_MONTH = int(START_DATE.split('-')[1]) - 1\n",
    "START_YEAR = START_DATE.split('-')[0]\n",
    "\n",
    "YST_DAY = YESTERDAY_DATE.split('-')[2]\n",
    "# In QuoteMedia, months start from 0, so we adjust this variable.\n",
    "YST_MONTH = int(YESTERDAY_DATE.split('-')[1]) - 1\n",
    "YST_YEAR = YESTERDAY_DATE.split('-')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1. Test: Get data from one source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 2.2370002679999743s\n",
      "2.24 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "\n",
    "import timeit\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "# %%timeit -n 1 -r 1\n",
    "# 8.67 s ± 1.53 s per loop (mean ± std. dev. of 3 runs, 3 loops each)\n",
    "\n",
    "import csv\n",
    "\n",
    "# response = requests.get(URL.format(sd=YST_DAY, sm=YST_MONTH, sy=YST_YEAR,\n",
    "response = requests.get(URL.format(sd=START_DATE, sm=START_MONTH, sy=START_YEAR,\n",
    "                                   ed=YST_DAY, em=YST_MONTH, ey=YST_YEAR,\n",
    "                                   sym='SPY'))\n",
    "# content = response.content.decode('utf-8')\n",
    "# data = [{k: v for k, v in row.items()}\n",
    "#         for row in csv.DictReader(content.splitlines(), skipinitialspace=True)]\n",
    "# print(len(data))\n",
    "# print(data[0])\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "print(\"elapsed time: {}s\".format(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "START_MONTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2. Test: Get data from all sources"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%timeit -n 1 -r 1\n",
    "# Takes too long, cancel this.\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "df = spark.read.parquet(DB_HOST+TABLE_STOCK_INFO_NASDAQ,\n",
    "                        DB_HOST+TABLE_STOCK_INFO_NYSE) \\\n",
    "     .select('Symbol').dropDuplicates()\n",
    "stocks = [row['Symbol'] for row in df.collect()]\n",
    "# print(\"num stocks: {}\".format(len(stocks)))\n",
    "\n",
    "for stock in tqdm(stocks):\n",
    "    response = requests.get(URL.format(sd=START_DATE, sm=START_MONTH, sy=START_YEAR,\n",
    "                                       ed=YST_DAY, em=YST_MONTH, ey=YST_YEAR,\n",
    "                                       sym=stock))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3. Test: Get data from one source and parallelize with Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.04 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "# response = requests.get(URL.format(sd=YST_DAY, sm=YST_MONTH, sy=YST_YEAR,\n",
    "response = requests.get(URL.format(sd=START_DATE, sm=START_MONTH, sy=START_YEAR,\n",
    "                                   ed=YST_DAY, em=YST_MONTH, ey=YST_YEAR,\n",
    "                                   sym='SPY'))\n",
    "content = response.content.decode('utf-8')\n",
    "data = spark.sparkContext.parallelize(content.splitlines())\n",
    "data = spark.read.csv(data, header=True) \\\n",
    "       .write.mode('overwrite').parquet('test/data/raw/test_prices')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4. Get data from all source in parallel then store them (also in parallel)\n",
    "\n",
    "```\n",
    "## Writing 369 rows, 2 requests:\n",
    "# 6.8 s ± 125 ms per loop (mean ± std. dev. of 3 runs, 3 loops each)\n",
    "## Writing 2 rows, 2 requests:\n",
    "# 5.86 s ± 133 ms per loop (mean ± std. dev. of 3 runs, 3 loops each)\n",
    "## writing 6468 rows, 10 requests:\n",
    "# 36.7 s ± 3.06 s per loop (mean ± std. dev. of 3 runs, 3 loops each)\n",
    "## No partition, 10 requests (incorrect rows, 6477):\n",
    "# 43.8 s ± 1.3 s per loop (mean ± std. dev. of 3 runs, 3 loops each)\n",
    "\n",
    "\n",
    "## Using temp table, writing 367 rows, 2 requests:\n",
    "# 7.81 s ± 386 ms per loop (mean ± std. dev. of 3 runs, 3 loops each)\n",
    "## Using temp table, writing 2 rows, 2 requests:\n",
    "# 7.05 s ± 289 ms per loop (mean ± std. dev. of 3 runs, 3 loops each)\n",
    "## Using temp table, writing 9 rows, 10 requests:\n",
    "# 20.3 s ± 85.8 ms per loop (mean ± std. dev. of 3 runs, 3 loops each)\n",
    "## Using temp table, writing 6495 rows, 10 requests:\n",
    "# 23.5 s ± 3.82 s per loop (mean ± std. dev. of 3 runs, 3 loops each)\n",
    "# Write as parquet\n",
    "# 41.9 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
    "```\n",
    "\n",
    "Conclusion: Better to use temp table written as CSV.\n",
    "\n",
    "### Code (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARN:root:Appending to table test_data/raw/prices\n",
      "WARN:root:    Creating temporary table test_data/raw/prices-temp\n",
      "WARN:root:    done! Now appending to table test_data/raw/prices\n",
      "WARN:root:done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.1 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "\n",
    "START_DAY = START_DATE.split('-')[2]\n",
    "# In QuoteMedia, months start from 0, so we adjust this variable.\n",
    "START_MONTH = int(START_DATE.split('-')[1]) - 1\n",
    "START_YEAR = START_DATE.split('-')[0]\n",
    "\n",
    "YST_DAY = YESTERDAY_DATE.split('-')[2]\n",
    "# In QuoteMedia, months start from 0, so we adjust this variable.\n",
    "YST_MONTH = int(YESTERDAY_DATE.split('-')[1]) - 1\n",
    "YST_YEAR = YESTERDAY_DATE.split('-')[0]\n",
    "\n",
    "create_table = not(spark_table_exists(DB_HOST, TABLE_STOCK_PRICES))\n",
    "\n",
    "def pull_prices_by_symbol(symbol):\n",
    "    \"\"\"\n",
    "    Return:\n",
    "        list of dicts [{'colname': value, ...}, ...]\n",
    "    \"\"\"\n",
    "    if create_table == True:\n",
    "        # If table does not exist, pull all data.\n",
    "        url = URL.format(sd=START_DAY, sm=START_MONTH, sy=START_YEAR,\n",
    "                         ed=YST_DAY, em=YST_MONTH, ey=YST_YEAR,\n",
    "                         sym=symbol)\n",
    "    else:\n",
    "        # If table had existed, pull yesterday's data.\n",
    "        url = URL.format(sd=YST_DAY, sm=YST_MONTH, sy=YST_YEAR,\n",
    "                         ed=YST_DAY, em=YST_MONTH, ey=YST_YEAR,\n",
    "                         sym=symbol)\n",
    "        \n",
    "    # Code for always overwrite without temp table\n",
    "#     url = URL.format(sd=START_DAY, sm=START_MONTH, sy=START_YEAR,\n",
    "#                      ed=YST_DAY, em=YST_MONTH, ey=YST_YEAR,\n",
    "#                      sym=symbol)\n",
    "\n",
    "    response = requests.get(url)\n",
    "    newdata = \"\"\n",
    "    if response.status_code in [200, 201]:\n",
    "        newdata = response.content.decode('utf-8')\n",
    "        newdata = newdata.replace('\\n', ','+symbol+'\\n')\n",
    "        newdata = newdata.replace('tradevol,'+symbol+'\\n', 'tradevol,symbol\\n')\n",
    "    return newdata\n",
    "\n",
    "schema = T.StringType()\n",
    "udf_pull_prices = F.udf(pull_prices_by_symbol, schema)\n",
    "    \n",
    "# Prepare list of stocks\n",
    "if STOCKS is not None and len(STOCKS) > 0:\n",
    "    rdd1 = spark.sparkContext.parallelize(STOCKS)\n",
    "    row_rdd = rdd1.map(lambda x: Row(x))\n",
    "    df = spark.createDataFrame(row_rdd,['Symbol'])\n",
    "else:\n",
    "    df = spark.read.parquet(DB_HOST+TABLE_STOCK_INFO_NASDAQ,\n",
    "                            DB_HOST+TABLE_STOCK_INFO_NYSE) \\\n",
    "         .select('Symbol').dropDuplicates()\n",
    "    if LIMIT is not None:\n",
    "        df = df.limit(LIMIT)\n",
    "\n",
    "df = df.withColumn('prices_csv', udf_pull_prices('Symbol'))\n",
    "\n",
    "df = df.select('prices_csv').where(df['prices_csv'] != '')\n",
    "\n",
    "table_name = DB_HOST+TABLE_STOCK_PRICES\n",
    "mode = 'overwrite'\n",
    "if create_table:\n",
    "    logger.warn(\"Creating table {}\".format(table_name))    \n",
    "else:\n",
    "    logger.warn(\"Appending to table {}\".format(table_name))\n",
    "    mode = 'append'\n",
    "\n",
    "# Repartition here is important so we may end up with multiple CSV-like files.\n",
    "# Without repartition, the headers are going to be written multiple times\n",
    "# in a single csv file.\n",
    "tempdir = DB_HOST+TABLE_STOCK_PRICES+'-temp'\n",
    "logger.warn(\"    Creating temporary table {}\".format(tempdir))\n",
    "\n",
    "numrows = df.count()\n",
    "df \\\n",
    "    .repartition(numrows).write.mode('overwrite') \\\n",
    "    .csv(tempdir, header=False, quote=\" \")\n",
    "\n",
    "\n",
    "if create_table:\n",
    "    logger.warn(\"    done! Now creating table {}\".format(table_name))\n",
    "else:\n",
    "    logger.warn(\"    done! Now appending to table {}\".format(table_name))\n",
    "\n",
    "spark.read.csv(tempdir, header=True, ignoreLeadingWhiteSpace=True, inferSchema=True) \\\n",
    ".write.mode(mode).csv(table_name, header=True)\n",
    "# .write.mode(mode).parquet(DB_HOST+TABLE_STOCK_PRICES)\n",
    "\n",
    "\n",
    "logger.warn(\"done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10458 entries, 0 to 10457\n",
      "Data columns (total 12 columns):\n",
      "date        10455 non-null datetime64[ns]\n",
      "open        10455 non-null object\n",
      "high        10455 non-null object\n",
      "low         10455 non-null object\n",
      "close       10455 non-null float64\n",
      "volume      10455 non-null float64\n",
      "changed     10455 non-null float64\n",
      "changep     10455 non-null object\n",
      "adjclose    10455 non-null float64\n",
      "tradeval    10455 non-null object\n",
      "tradevol    10455 non-null float64\n",
      "symbol      10455 non-null object\n",
      "dtypes: datetime64[ns](1), float64(5), object(6)\n",
      "memory usage: 980.5+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>changed</th>\n",
       "      <th>changep</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>tradeval</th>\n",
       "      <th>tradevol</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-12-13</td>\n",
       "      <td>196.40</td>\n",
       "      <td>196.80</td>\n",
       "      <td>193.17</td>\n",
       "      <td>194.11</td>\n",
       "      <td>18806020.0</td>\n",
       "      <td>-2.64</td>\n",
       "      <td>-1.34%</td>\n",
       "      <td>194.11</td>\n",
       "      <td>3657544992.09</td>\n",
       "      <td>192331.0</td>\n",
       "      <td>FB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-12-12</td>\n",
       "      <td>202.35</td>\n",
       "      <td>203.66</td>\n",
       "      <td>194.10</td>\n",
       "      <td>196.75</td>\n",
       "      <td>23766986.0</td>\n",
       "      <td>-5.51</td>\n",
       "      <td>-2.72%</td>\n",
       "      <td>196.75</td>\n",
       "      <td>4710540903.58</td>\n",
       "      <td>208246.0</td>\n",
       "      <td>FB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-12-11</td>\n",
       "      <td>200.28</td>\n",
       "      <td>202.63</td>\n",
       "      <td>200.28</td>\n",
       "      <td>202.26</td>\n",
       "      <td>8041827.0</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.69%</td>\n",
       "      <td>202.26</td>\n",
       "      <td>1622090474.60</td>\n",
       "      <td>77975.0</td>\n",
       "      <td>FB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-12-10</td>\n",
       "      <td>201.66</td>\n",
       "      <td>202.05</td>\n",
       "      <td>200.15</td>\n",
       "      <td>200.87</td>\n",
       "      <td>9485568.0</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-0.23%</td>\n",
       "      <td>200.87</td>\n",
       "      <td>1905136360.62</td>\n",
       "      <td>88428.0</td>\n",
       "      <td>FB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-12-09</td>\n",
       "      <td>200.65</td>\n",
       "      <td>203.1418</td>\n",
       "      <td>200.21</td>\n",
       "      <td>201.34</td>\n",
       "      <td>12013218.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>201.34</td>\n",
       "      <td>2427805092.89</td>\n",
       "      <td>102640.0</td>\n",
       "      <td>FB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date    open      high     low   close      volume  changed changep  \\\n",
       "0 2019-12-13  196.40    196.80  193.17  194.11  18806020.0    -2.64  -1.34%   \n",
       "1 2019-12-12  202.35    203.66  194.10  196.75  23766986.0    -5.51  -2.72%   \n",
       "2 2019-12-11  200.28    202.63  200.28  202.26   8041827.0     1.39   0.69%   \n",
       "3 2019-12-10  201.66    202.05  200.15  200.87   9485568.0    -0.47  -0.23%   \n",
       "4 2019-12-09  200.65  203.1418  200.21  201.34  12013218.0     0.29   0.14%   \n",
       "\n",
       "   adjclose       tradeval  tradevol symbol  \n",
       "0    194.11  3657544992.09  192331.0     FB  \n",
       "1    196.75  4710540903.58  208246.0     FB  \n",
       "2    202.26  1622090474.60   77975.0     FB  \n",
       "3    200.87  1905136360.62   88428.0     FB  \n",
       "4    201.34  2427805092.89  102640.0     FB  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_temp = spark.read.csv(DB_HOST+TABLE_STOCK_PRICES+'-temp', header=True, ignoreLeadingWhiteSpace=True, inferSchema=True).toPandas()\n",
    "print(pdf_temp.info())\n",
    "pdf_temp.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10456 entries, 0 to 10455\n",
      "Data columns (total 12 columns):\n",
      "date        10455 non-null datetime64[ns]\n",
      "open        10455 non-null object\n",
      "high        10455 non-null object\n",
      "low         10455 non-null object\n",
      "close       10455 non-null float64\n",
      "volume      10455 non-null float64\n",
      "changed     10455 non-null float64\n",
      "changep     10455 non-null object\n",
      "adjclose    10455 non-null float64\n",
      "tradeval    10455 non-null object\n",
      "tradevol    10455 non-null float64\n",
      "symbol      10455 non-null object\n",
      "dtypes: datetime64[ns](1), float64(5), object(6)\n",
      "memory usage: 980.3+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>changed</th>\n",
       "      <th>changep</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>tradeval</th>\n",
       "      <th>tradevol</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-04-19</td>\n",
       "      <td>25.62</td>\n",
       "      <td>25.96</td>\n",
       "      <td>25.33</td>\n",
       "      <td>25.73</td>\n",
       "      <td>20353547.0</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>25.7300</td>\n",
       "      <td>523595607.18</td>\n",
       "      <td>66068.0</td>\n",
       "      <td>FB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-04-22</td>\n",
       "      <td>99.35</td>\n",
       "      <td>99.66</td>\n",
       "      <td>98.38</td>\n",
       "      <td>99.32</td>\n",
       "      <td>5609009.0</td>\n",
       "      <td>-0.493</td>\n",
       "      <td>-0.60%</td>\n",
       "      <td>81.5900</td>\n",
       "      <td>555207178.14</td>\n",
       "      <td>32582.0</td>\n",
       "      <td>MCD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-04-26</td>\n",
       "      <td>100.83</td>\n",
       "      <td>100.99</td>\n",
       "      <td>100.40</td>\n",
       "      <td>100.89</td>\n",
       "      <td>3113532.0</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>-0.05%</td>\n",
       "      <td>82.8798</td>\n",
       "      <td>313733616.64</td>\n",
       "      <td>16412.0</td>\n",
       "      <td>MCD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-05-13</td>\n",
       "      <td>26.60</td>\n",
       "      <td>27.325</td>\n",
       "      <td>26.531</td>\n",
       "      <td>26.82</td>\n",
       "      <td>29009648.0</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.52%</td>\n",
       "      <td>26.8200</td>\n",
       "      <td>782579320.46</td>\n",
       "      <td>90803.0</td>\n",
       "      <td>FB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-07-10</td>\n",
       "      <td>291.41</td>\n",
       "      <td>293.34</td>\n",
       "      <td>289.40</td>\n",
       "      <td>292.33</td>\n",
       "      <td>1822877.0</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.27%</td>\n",
       "      <td>292.3300</td>\n",
       "      <td>531832345.31</td>\n",
       "      <td>11812.0</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date    open    high     low   close      volume  changed changep  \\\n",
       "0 2013-04-19   25.62   25.96   25.33   25.73  20353547.0    0.040   0.16%   \n",
       "1 2013-04-22   99.35   99.66   98.38   99.32   5609009.0   -0.493  -0.60%   \n",
       "2 2013-04-26  100.83  100.99  100.40  100.89   3113532.0   -0.041  -0.05%   \n",
       "3 2013-05-13   26.60  27.325  26.531   26.82  29009648.0    0.140   0.52%   \n",
       "4 2013-07-10  291.41  293.34  289.40  292.33   1822877.0    0.800   0.27%   \n",
       "\n",
       "   adjclose      tradeval  tradevol symbol  \n",
       "0   25.7300  523595607.18   66068.0     FB  \n",
       "1   81.5900  555207178.14   32582.0    MCD  \n",
       "2   82.8798  313733616.64   16412.0    MCD  \n",
       "3   26.8200  782579320.46   90803.0     FB  \n",
       "4  292.3300  531832345.31   11812.0   AMZN  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf = spark.read.csv(DB_HOST+TABLE_STOCK_PRICES, header=True, inferSchema=True) \\\n",
    "    .dropDuplicates(['date', 'symbol']).toPandas()\n",
    "print(pdf.info())\n",
    "pdf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>changed</th>\n",
       "      <th>changep</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>tradeval</th>\n",
       "      <th>tradevol</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5227</th>\n",
       "      <td>2013-04-02</td>\n",
       "      <td>262.40</td>\n",
       "      <td>265.89</td>\n",
       "      <td>260.55</td>\n",
       "      <td>263.322</td>\n",
       "      <td>2631038.0</td>\n",
       "      <td>1.712</td>\n",
       "      <td>0.65%</td>\n",
       "      <td>263.3220</td>\n",
       "      <td>693325169.20</td>\n",
       "      <td>17760.0</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>2013-04-02</td>\n",
       "      <td>25.77</td>\n",
       "      <td>26.12</td>\n",
       "      <td>25.30</td>\n",
       "      <td>25.420</td>\n",
       "      <td>35124893.0</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>-0.43%</td>\n",
       "      <td>25.4200</td>\n",
       "      <td>904220577.12</td>\n",
       "      <td>107077.0</td>\n",
       "      <td>FB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>2013-04-02</td>\n",
       "      <td>99.40</td>\n",
       "      <td>100.42</td>\n",
       "      <td>99.025</td>\n",
       "      <td>100.260</td>\n",
       "      <td>5136501.0</td>\n",
       "      <td>0.994</td>\n",
       "      <td>1.22%</td>\n",
       "      <td>82.3622</td>\n",
       "      <td>513202156.02</td>\n",
       "      <td>24959.0</td>\n",
       "      <td>MCD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9771</th>\n",
       "      <td>2013-04-02</td>\n",
       "      <td>183.90</td>\n",
       "      <td>185.1799</td>\n",
       "      <td>176.10</td>\n",
       "      <td>176.690</td>\n",
       "      <td>4610979.0</td>\n",
       "      <td>-0.820</td>\n",
       "      <td>-3.15%</td>\n",
       "      <td>25.2414</td>\n",
       "      <td>828031668.71</td>\n",
       "      <td>27837.0</td>\n",
       "      <td>NFLX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5432</th>\n",
       "      <td>2013-04-02</td>\n",
       "      <td>43.60</td>\n",
       "      <td>45.50</td>\n",
       "      <td>43.5101</td>\n",
       "      <td>44.340</td>\n",
       "      <td>6621439.0</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.93%</td>\n",
       "      <td>44.3400</td>\n",
       "      <td>294906438.13</td>\n",
       "      <td>28077.0</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date    open      high      low    close      volume  changed  \\\n",
       "5227 2013-04-02  262.40    265.89   260.55  263.322   2631038.0    1.712   \n",
       "1986 2013-04-02   25.77     26.12    25.30   25.420  35124893.0   -0.110   \n",
       "2041 2013-04-02   99.40    100.42   99.025  100.260   5136501.0    0.994   \n",
       "9771 2013-04-02  183.90  185.1799   176.10  176.690   4610979.0   -0.820   \n",
       "5432 2013-04-02   43.60     45.50  43.5101   44.340   6621439.0    0.410   \n",
       "\n",
       "     changep  adjclose      tradeval  tradevol symbol  \n",
       "5227   0.65%  263.3220  693325169.20   17760.0   AMZN  \n",
       "1986  -0.43%   25.4200  904220577.12  107077.0     FB  \n",
       "2041   1.22%   82.3622  513202156.02   24959.0    MCD  \n",
       "9771  -3.15%   25.2414  828031668.71   27837.0   NFLX  \n",
       "5432   0.93%   44.3400  294906438.13   28077.0   TSLA  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.sort_values(by=['date', 'symbol'], ascending=True).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality-check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass into `args` argument\n",
    "\n",
    "STOCKS = ['FB', 'GOOG', 'AMZN', 'TRMT', 'TSLA', 'MCD', 'NFLX']\n",
    "DB_HOST = ''\n",
    "\n",
    "# Table names: update to add '/' in the final code.\n",
    "TABLE_STOCK_INFO_NASDAQ = 'test_data/raw/stock_info_nasdaq'\n",
    "TABLE_STOCK_INFO_NYSE = 'test_data/raw/stock_info_nyse'\n",
    "TABLE_STOCK_PRICES = 'test_data/raw/prices'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARN:root:(SUCCESS) Table test_data/raw/prices has 10458 rows.\n"
     ]
    }
   ],
   "source": [
    "if STOCKS is None or len(STOCKS) == 0:\n",
    "    check_basic_quality(logger, DB_HOST, TABLE_STOCK_INFO_NASDAQ)\n",
    "    check_basic_quality(logger, DB_HOST, TABLE_STOCK_INFO_NYSE)\n",
    "check_basic_quality(logger, DB_HOST, TABLE_STOCK_PRICES, table_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Combine Datasets\n",
    "\n",
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass into `args` argument\n",
    "\n",
    "YESTERDAY_DATE = '2019-12-12'\n",
    "AWS_ACCESS_KEY_ID = config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "AWS_SECRET_ACCESS_KEY = config['AWS']['AWS_SECRET_ACCESS_KEY']\n",
    "DB_HOST = ''\n",
    "\n",
    "# Table names: update to add '/' in the final code.\n",
    "TABLE_STOCK_PRICES = 'test_data/raw/prices'\n",
    "TABLE_SHORT_INTERESTS_NASDAQ = 'test_data/raw/short_interests_nasdaq' \n",
    "TABLE_SHORT_INTERESTS_NYSE = 'test_data/raw/short_interests_nyse'\n",
    "TABLE_SHORT_ANALYSIS = 'test_data/processed/short_analysis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARN:root:Creating table test_data/processed/short_analysis\n",
      "WARN:root:done!\n"
     ]
    }
   ],
   "source": [
    "create_table = not(spark_table_exists(DB_HOST, TABLE_SHORT_ANALYSIS))\n",
    "\n",
    "sdf_shorts = spark.read.parquet(DB_HOST+TABLE_SHORT_INTERESTS_NASDAQ, DB_HOST+TABLE_SHORT_INTERESTS_NYSE)\n",
    "sdf_shorts = sdf_shorts.groupby(['Date', 'Symbol']) \\\n",
    "                 .agg(F.sum(sdf_shorts['ShortExemptVolume']).alias('short_exempt_volume'),\n",
    "                      F.sum(sdf_shorts['ShortVolume']).alias('short_volume'),\n",
    "                      F.sum(sdf_shorts['TotalVolume']).alias('total_volume'),\n",
    "                      F.first(sdf_shorts['SourceURL']).alias('source_url')\n",
    "                     )\n",
    "sdf_prices = spark.read.csv(DB_HOST+TABLE_STOCK_PRICES, header=True, inferSchema=True) \\\n",
    "             .dropDuplicates(['date', 'symbol'])\n",
    "sdf_prices = sdf_prices.withColumn('date', sdf_prices['date'].cast(T.DateType()))\n",
    "\n",
    "if create_table == False:\n",
    "    sdf_shorts = sdf_shorts.filter(sdf_shorts['Date'] >= F.to_date(F.lit(YESTERDAY_DATE)))\n",
    "    sdf_prices = sdf_prices.filter(sdf_prices['date'] >= F.to_date(F.lit(YESTERDAY_DATE)))\n",
    "\n",
    "sdf_short_analysis = sdf_shorts.join(sdf_prices, (sdf_shorts['Date'] == sdf_prices['date']) & \\\n",
    "                                     (sdf_shorts['Symbol'] == sdf_prices['symbol']), how='inner') \\\n",
    "                               .drop(sdf_shorts['Date']).drop(sdf_shorts['Symbol'])\n",
    "\n",
    "mode = 'overwrite'\n",
    "if create_table == False:\n",
    "    logger.warn(\"Appending to table {}\".format(DB_HOST+TABLE_SHORT_ANALYSIS))\n",
    "    mode = 'append'\n",
    "else:\n",
    "    logger.warn(\"Creating table {}\".format(DB_HOST+TABLE_SHORT_ANALYSIS))\n",
    "\n",
    "sdf_short_analysis.write.mode(mode).parquet(DB_HOST+TABLE_SHORT_ANALYSIS)\n",
    "logger.warn(\"done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10796 entries, 0 to 10795\n",
      "Data columns (total 6 columns):\n",
      "Date                   10796 non-null object\n",
      "Symbol                 10796 non-null object\n",
      "short_exempt_volume    10796 non-null float64\n",
      "short_volume           10796 non-null float64\n",
      "total_volume           10796 non-null float64\n",
      "source_url             10796 non-null object\n",
      "dtypes: float64(3), object(3)\n",
      "memory usage: 506.1+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10456 entries, 0 to 10455\n",
      "Data columns (total 12 columns):\n",
      "date        10455 non-null object\n",
      "open        10455 non-null object\n",
      "high        10455 non-null object\n",
      "low         10455 non-null object\n",
      "close       10455 non-null float64\n",
      "volume      10455 non-null float64\n",
      "changed     10455 non-null float64\n",
      "changep     10455 non-null object\n",
      "adjclose    10455 non-null float64\n",
      "tradeval    10455 non-null object\n",
      "tradevol    10455 non-null float64\n",
      "symbol      10455 non-null object\n",
      "dtypes: float64(5), object(7)\n",
      "memory usage: 980.3+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10394 entries, 0 to 10393\n",
      "Data columns (total 16 columns):\n",
      "short_exempt_volume    10394 non-null float64\n",
      "short_volume           10394 non-null float64\n",
      "total_volume           10394 non-null float64\n",
      "source_url             10394 non-null object\n",
      "date                   10394 non-null object\n",
      "open                   10394 non-null object\n",
      "high                   10394 non-null object\n",
      "low                    10394 non-null object\n",
      "close                  10394 non-null float64\n",
      "volume                 10394 non-null int32\n",
      "changed                10394 non-null float64\n",
      "changep                10394 non-null object\n",
      "adjclose               10394 non-null float64\n",
      "tradeval               10394 non-null object\n",
      "tradevol               10394 non-null int32\n",
      "symbol                 10394 non-null object\n",
      "dtypes: float64(6), int32(2), object(8)\n",
      "memory usage: 1.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df_short = sdf_shorts.toPandas()\n",
    "df_prices = sdf_prices.toPandas()\n",
    "df_short_analysis = sdf_short_analysis.toPandas()\n",
    "\n",
    "print(df_short.info())\n",
    "print(df_prices.info())\n",
    "print(df_short_analysis.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>short_exempt_volume</th>\n",
       "      <th>short_volume</th>\n",
       "      <th>total_volume</th>\n",
       "      <th>source_url</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>changed</th>\n",
       "      <th>changep</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>tradeval</th>\n",
       "      <th>tradevol</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>418961.0</td>\n",
       "      <td>753385.0</td>\n",
       "      <td>https://www.quandl.com/api/v3/datasets/FINRA/F...</td>\n",
       "      <td>2013-05-01</td>\n",
       "      <td>215.92</td>\n",
       "      <td>217.389</td>\n",
       "      <td>211.65</td>\n",
       "      <td>212.91</td>\n",
       "      <td>2622654</td>\n",
       "      <td>-0.451</td>\n",
       "      <td>-1.46%</td>\n",
       "      <td>30.4157</td>\n",
       "      <td>561027949.42</td>\n",
       "      <td>14673</td>\n",
       "      <td>NFLX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37360.0</td>\n",
       "      <td>6060485.0</td>\n",
       "      <td>20502608.0</td>\n",
       "      <td>https://www.quandl.com/api/v3/datasets/FINRA/F...</td>\n",
       "      <td>2013-05-06</td>\n",
       "      <td>28.33</td>\n",
       "      <td>28.46</td>\n",
       "      <td>27.48</td>\n",
       "      <td>27.57</td>\n",
       "      <td>43862625</td>\n",
       "      <td>-0.741</td>\n",
       "      <td>-2.62%</td>\n",
       "      <td>27.5700</td>\n",
       "      <td>1219158766.94</td>\n",
       "      <td>120016</td>\n",
       "      <td>FB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>635427.0</td>\n",
       "      <td>1388246.0</td>\n",
       "      <td>https://www.quandl.com/api/v3/datasets/FINRA/F...</td>\n",
       "      <td>2013-05-06</td>\n",
       "      <td>209.63</td>\n",
       "      <td>212.45</td>\n",
       "      <td>204.02</td>\n",
       "      <td>210.69</td>\n",
       "      <td>4532918</td>\n",
       "      <td>-0.394</td>\n",
       "      <td>-1.29%</td>\n",
       "      <td>30.0985</td>\n",
       "      <td>949314738.05</td>\n",
       "      <td>26760</td>\n",
       "      <td>NFLX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300.0</td>\n",
       "      <td>451077.0</td>\n",
       "      <td>952404.0</td>\n",
       "      <td>https://www.quandl.com/api/v3/datasets/FINRA/F...</td>\n",
       "      <td>2013-05-09</td>\n",
       "      <td>258.73</td>\n",
       "      <td>263.55</td>\n",
       "      <td>256.88</td>\n",
       "      <td>260.16</td>\n",
       "      <td>2769255</td>\n",
       "      <td>1.480</td>\n",
       "      <td>0.57%</td>\n",
       "      <td>260.1600</td>\n",
       "      <td>723085024.78</td>\n",
       "      <td>17822</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>342728.0</td>\n",
       "      <td>1335921.0</td>\n",
       "      <td>https://www.quandl.com/api/v3/datasets/FINRA/F...</td>\n",
       "      <td>2013-06-28</td>\n",
       "      <td>276.19</td>\n",
       "      <td>279.83</td>\n",
       "      <td>276.19</td>\n",
       "      <td>277.69</td>\n",
       "      <td>3193262</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.05%</td>\n",
       "      <td>277.6900</td>\n",
       "      <td>889020787.27</td>\n",
       "      <td>14332</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   short_exempt_volume  short_volume  total_volume  \\\n",
       "0                  0.0      418961.0      753385.0   \n",
       "1              37360.0     6060485.0    20502608.0   \n",
       "2                  0.0      635427.0     1388246.0   \n",
       "3                300.0      451077.0      952404.0   \n",
       "4                  0.0      342728.0     1335921.0   \n",
       "\n",
       "                                          source_url        date    open  \\\n",
       "0  https://www.quandl.com/api/v3/datasets/FINRA/F...  2013-05-01  215.92   \n",
       "1  https://www.quandl.com/api/v3/datasets/FINRA/F...  2013-05-06   28.33   \n",
       "2  https://www.quandl.com/api/v3/datasets/FINRA/F...  2013-05-06  209.63   \n",
       "3  https://www.quandl.com/api/v3/datasets/FINRA/F...  2013-05-09  258.73   \n",
       "4  https://www.quandl.com/api/v3/datasets/FINRA/F...  2013-06-28  276.19   \n",
       "\n",
       "      high     low   close    volume  changed changep  adjclose  \\\n",
       "0  217.389  211.65  212.91   2622654   -0.451  -1.46%   30.4157   \n",
       "1    28.46   27.48   27.57  43862625   -0.741  -2.62%   27.5700   \n",
       "2   212.45  204.02  210.69   4532918   -0.394  -1.29%   30.0985   \n",
       "3   263.55  256.88  260.16   2769255    1.480   0.57%  260.1600   \n",
       "4   279.83  276.19  277.69   3193262    0.140   0.05%  277.6900   \n",
       "\n",
       "        tradeval  tradevol symbol  \n",
       "0   561027949.42     14673   NFLX  \n",
       "1  1219158766.94    120016     FB  \n",
       "2   949314738.05     26760   NFLX  \n",
       "3   723085024.78     17822   AMZN  \n",
       "4   889020787.27     14332   AMZN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.parquet(DB_HOST+TABLE_SHORT_ANALYSIS).toPandas().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality-check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass into `args` argument\n",
    "\n",
    "DB_HOST = ''\n",
    "\n",
    "# Table names: update to add '/' in the final code.\n",
    "TABLE_SHORT_ANALYSIS = 'test_data/processed/short_analysis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARN:root:(SUCCESS) Table test_data/processed/short_analysis has 10394 rows.\n"
     ]
    }
   ],
   "source": [
    "check_basic_quality(logger, DB_HOST, TABLE_SHORT_ANALYSIS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = spark.read.parquet(config['App']['DB_HOST']+config['App']['TABLE_SHORT_ANALYSIS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sdf.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>short_exempt_volume</th>\n",
       "      <th>short_volume</th>\n",
       "      <th>total_volume</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>changed</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>tradevol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.054800e+04</td>\n",
       "      <td>1.054800e+04</td>\n",
       "      <td>1.054800e+04</td>\n",
       "      <td>10548.000000</td>\n",
       "      <td>1.054800e+04</td>\n",
       "      <td>10548.000000</td>\n",
       "      <td>10548.000000</td>\n",
       "      <td>1.054800e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.186437e+04</td>\n",
       "      <td>1.403028e+06</td>\n",
       "      <td>3.208060e+06</td>\n",
       "      <td>394.143509</td>\n",
       "      <td>9.086290e+06</td>\n",
       "      <td>0.389712</td>\n",
       "      <td>374.410873</td>\n",
       "      <td>6.666282e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.619000e+04</td>\n",
       "      <td>2.289725e+06</td>\n",
       "      <td>5.337051e+06</td>\n",
       "      <td>422.500286</td>\n",
       "      <td>1.448612e+07</td>\n",
       "      <td>11.274337</td>\n",
       "      <td>429.671097</td>\n",
       "      <td>6.752694e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.940000</td>\n",
       "      <td>5.300000e+01</td>\n",
       "      <td>-139.360000</td>\n",
       "      <td>3.612400</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>2.772368e+05</td>\n",
       "      <td>6.956500e+05</td>\n",
       "      <td>120.627500</td>\n",
       "      <td>2.423723e+06</td>\n",
       "      <td>-1.401000</td>\n",
       "      <td>99.175000</td>\n",
       "      <td>2.628525e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.183000e+03</td>\n",
       "      <td>6.329955e+05</td>\n",
       "      <td>1.455506e+06</td>\n",
       "      <td>221.885000</td>\n",
       "      <td>4.423890e+06</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>196.520200</td>\n",
       "      <td>4.293400e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.187750e+03</td>\n",
       "      <td>1.543929e+06</td>\n",
       "      <td>3.499728e+06</td>\n",
       "      <td>496.172500</td>\n",
       "      <td>9.444361e+06</td>\n",
       "      <td>2.089250</td>\n",
       "      <td>428.165000</td>\n",
       "      <td>8.723925e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.653923e+06</td>\n",
       "      <td>4.887740e+07</td>\n",
       "      <td>1.201625e+08</td>\n",
       "      <td>2039.510000</td>\n",
       "      <td>3.653806e+08</td>\n",
       "      <td>558.460000</td>\n",
       "      <td>2039.510000</td>\n",
       "      <td>1.312878e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       short_exempt_volume  short_volume  total_volume         close  \\\n",
       "count         1.054800e+04  1.054800e+04  1.054800e+04  10548.000000   \n",
       "mean          1.186437e+04  1.403028e+06  3.208060e+06    394.143509   \n",
       "std           4.619000e+04  2.289725e+06  5.337051e+06    422.500286   \n",
       "min           0.000000e+00  1.000000e+00  1.000000e+00      3.940000   \n",
       "25%           5.000000e+02  2.772368e+05  6.956500e+05    120.627500   \n",
       "50%           2.183000e+03  6.329955e+05  1.455506e+06    221.885000   \n",
       "75%           8.187750e+03  1.543929e+06  3.499728e+06    496.172500   \n",
       "max           1.653923e+06  4.887740e+07  1.201625e+08   2039.510000   \n",
       "\n",
       "             volume       changed      adjclose      tradevol  \n",
       "count  1.054800e+04  10548.000000  10548.000000  1.054800e+04  \n",
       "mean   9.086290e+06      0.389712    374.410873  6.666282e+04  \n",
       "std    1.448612e+07     11.274337    429.671097  6.752694e+04  \n",
       "min    5.300000e+01   -139.360000      3.612400  0.000000e+00  \n",
       "25%    2.423723e+06     -1.401000     99.175000  2.628525e+04  \n",
       "50%    4.423890e+06      0.080000    196.520200  4.293400e+04  \n",
       "75%    9.444361e+06      2.089250    428.165000  8.723925e+04  \n",
       "max    3.653806e+08    558.460000   2039.510000  1.312878e+06  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10548 entries, 0 to 10547\n",
      "Data columns (total 14 columns):\n",
      "short_exempt_volume    10548 non-null float64\n",
      "short_volume           10548 non-null float64\n",
      "total_volume           10548 non-null float64\n",
      "source_url             10548 non-null object\n",
      "open                   10548 non-null object\n",
      "high                   10548 non-null object\n",
      "low                    10548 non-null object\n",
      "close                  10548 non-null float64\n",
      "volume                 10548 non-null int32\n",
      "changed                10548 non-null float64\n",
      "changep                10548 non-null object\n",
      "adjclose               10548 non-null float64\n",
      "tradeval               10548 non-null object\n",
      "tradevol               10548 non-null int32\n",
      "dtypes: float64(6), int32(2), object(6)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- Best practices: https://towardsdatascience.com/apache-airflow-tips-and-best-practices-ff64ce92ef8\n",
    "- Write/store dataframe as textfile: https://stackoverflow.com/questions/44537889/write-store-dataframe-in-text-file\n",
    "- Delete hdfs path: https://stackoverflow.com/a/55952480/278191\n",
    "- Delete hdfs path in S3: http://bigdatatech.taleia.software/2015/12/28/deleting-a-amazon-s3-path-from-apache-spark/\n",
    "- Import java class in python: https://stackoverflow.com/questions/33544105/running-custom-java-class-in-pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
